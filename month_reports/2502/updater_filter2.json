{
    "foundation-models": [
        {
            "year": "2025.02",
            "title": "Large Cognition Model: Towards Pretrained EEG Foundation Model",
            "team": "Aidan Hung-Wen Tsai",
            "team website": "",
            "affiliation": "",
            "domain": "EEG foundation model",
            "abstract": "Electroencephalography provides a non-invasive window into brain activity, offering valuable insights for neurological research, brain-computer interfaces, and clinical diagnostics. However, the development of robust machine learning models for EEG analysis is hindered by the scarcity of large-scale, well-annotated datasets and the inherent variability of EEG signals across subjects and recording conditions. Inspired by the success of foundation models in natural language processing and computer vision, we propose the Large Cognition Model-a transformer-based foundation model designed to generalize across diverse EEG datasets and downstream tasks. Unlike traditional approaches, our proposed transformer-based architecture demonstrates strong generalization capabilities across datasets and tasks, even without pretraining, surpassing some existing EEG universal models on specific downstream applications. LCM leverages large-scale self-supervised learning techniques to capture universal EEG representations, enabling efficient fine-tuning for applications such as cognitive state decoding, disease classification, and neurofeedback systems. We introduce a novel architecture that integrates temporal and spectral attention mechanisms, optimizing the model's ability to extract meaningful features from raw EEG signals. Extensive evaluations demonstrate that LCM outperforms state-of-the-art approaches across multiple EEG benchmarks, exhibiting strong cross-subject and cross-task generalization. Our findings highlight the potential of pretrained EEG foundation models to accelerate advancements in neuroscience, personalized medicine, and BCI technology.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/92e6303157e9044ada38869c8d3c318882bbb9b6",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2502.17464",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.02",
            "title": "Omni-DNA: A Unified Genomic Foundation Model for Cross-Modal and Multi-Task Learning",
            "team": "Caihua Shan",
            "team website": "",
            "affiliation": "",
            "domain": "Cross-modal genomic foundation model",
            "abstract": "Large Language Models (LLMs) demonstrate remarkable generalizability across diverse tasks, yet genomic foundation models (GFMs) still require separate finetuning for each downstream application, creating significant overhead as model sizes grow. Moreover, existing GFMs are constrained by rigid output formats, limiting their applicability to various genomic tasks. In this work, we revisit the transformer-based auto-regressive models and introduce Omni-DNA, a family of cross-modal multi-task models ranging from 20 million to 1 billion parameters. Our approach consists of two stages: (i) pretraining on DNA sequences with next token prediction objective, and (ii) expanding the multi-modal task-specific tokens and finetuning for multiple downstream tasks simultaneously. When evaluated on the Nucleotide Transformer and GB benchmarks, Omni-DNA achieves state-of-the-art performance on 18 out of 26 tasks. Through multi-task finetuning, Omni-DNA addresses 10 acetylation and methylation tasks at once, surpassing models trained on each task individually. Finally, we design two complex genomic tasks, DNA2Function and Needle-in-DNA, which map DNA sequences to textual functional descriptions and images, respectively, indicating Omni-DNA's cross-modal capabilities to broaden the scope of genomic applications. All the models are available through https://huggingface.co/collections/zehui127",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/7b9c7b43df7282797547f622788389d09cf5b3d2",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2502.03499",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.02",
            "title": "GENERator: A Long-Context Generative Genomic Foundation Model",
            "team": "Zheng Wang",
            "team website": "",
            "affiliation": "",
            "domain": "Generative genomic foundation model",
            "abstract": "Advancements in DNA sequencing technologies have significantly improved our ability to decode genomic sequences. However, the prediction and interpretation of these sequences remain challenging due to the intricate nature of genetic material. Large language models (LLMs) have introduced new opportunities for biological sequence analysis. Recent developments in genomic language models have underscored the potential of LLMs in deciphering DNA sequences. Nonetheless, existing models often face limitations in robustness and application scope, primarily due to constraints in model structure and training data scale. To address these limitations, we present GENERator, a generative genomic foundation model featuring a context length of 98k base pairs (bp) and 1.2B parameters. Trained on an expansive dataset comprising 386B bp of eukaryotic DNA, the GENERator demonstrates state-of-the-art performance across both established and newly proposed benchmarks. The model adheres to the central dogma of molecular biology, accurately generating protein-coding sequences that translate into proteins structurally analogous to known families. It also shows significant promise in sequence optimization, particularly through the prompt-responsive generation of enhancer sequences with specific activity profiles. These capabilities position the GENERator as a pivotal tool for genomic research and biotechnological advancement, enhancing our ability to interpret and predict complex biological systems and enabling precise genomic interventions. Implementation details and supplementary resources are available at https://github.com/GenerTeam/GENERator.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/4f98b1f62cfd71e2d2bf44156a5a971029cf4c16",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2502.07272",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.02",
            "title": "Top-DTI: Integrating Topological Deep Learning and Large Language Models for Drug Target Interaction Prediction",
            "team": "S. Bozdag",
            "team website": "",
            "affiliation": "University of North Texas",
            "domain": "Drug\u2013target interaction prediction framework",
            "abstract": "Motivation The accurate prediction of drug\u2013target interactions (DTI) is a crucial step in drug discovery, providing a foundation for identifying novel therapeutics. Traditional drug development is both costly and time-consuming, often spanning over a decade. Computational approaches help narrow the pool of compound candidates, offering significant starting points for experimental validation. In this study, we propose Top-DTI framework for predicting DTI by integrating topological data analysis (TDA) with large language models (LLMs). Top-DTI leverages persistent homology to extract topological features from protein contact maps and drug molecular images. Simultaneously, protein and drug LLMs generate semantically rich embeddings that capture sequential and contextual information from protein sequences and drug SMILES strings. By combining these complementary features, Top-DTI enhances predictive performance and robustness. Results Experimental results on the public BioSNAP and Human DTI benchmark datasets demonstrate that the proposed Top-DTI model outperforms state-of-the-art approaches across multiple evaluation metrics, including AUROC, AUPRC, sensitivity, and specificity. Furthermore, the Top-DTI model achieves superior performance in the challenging cold-split scenario, where the test and validation sets contain drugs or targets absent from the training set. This setting simulates real-world scenarios and highlights the robustness of the model. Notably, incorporating topological features alongside LLM embeddings significantly improves predictive performance, underscoring the value of integrating structural and sequence-based representations. Availability The data and source code of Top-DTI is available at https://github.com/bozdaglab/Top_DTI under Creative Commons Attribution Non Commercial 4.0 International Public License.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/c7aa64927a5600588c7e6600aafcf1a3b0d3e41b",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.02.07.637146",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2025.02",
            "title": "AI-enabled alkaline-resistant evolution of protein to apply in mass production",
            "team": "Liang Hong",
            "team website": "",
            "affiliation": "",
            "domain": "LLM-driven protein evolution for alkaline resistance",
            "abstract": "Artificial intelligence (AI) models have been used to study the compositional regularities of proteins in nature, enabling it to assist in protein design to improve the efficiency of protein engineering and reduce manufacturing cost. However, in industrial settings, proteins are often required to work in extreme environments where they are relatively scarce or even non-existent in nature. Since such proteins are almost absent in the training datasets, it is uncertain whether AI model possesses the capability of evolving the protein to adapt extreme conditions. Antibodies are crucial components of affinity chromatography, and they are hoped to remain active at the extreme environments where most proteins cannot tolerate. In this study, we applied an advanced large language model (LLM), the Pro-PRIME model, to improve the alkali resistance of a representative antibody, a VHH antibody capable of binding to growth hormone. Through two rounds of design, we ensured that the selected mutant has enhanced functionality, including higher thermal stability, extreme pH resistance and stronger affinity, thereby validating the generalized capability of the LLM in meeting specific demands. To the best of our knowledge, this is the first LLM-designed protein product, which is successfully applied in mass production.",
            "venue": "eLife",
            "paperUrl": "https://www.semanticscholar.org/paper/91b7e83815ad6a4da3232dd62f3799634ee43dda",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.7554/eLife.102788",
            "reason_for_inclusion": "High quality: Published in eLife, a top-tier journal."
        },
        {
            "year": "2025.02",
            "title": "Genome modeling and design across all domains of life with Evo 2",
            "team": "Arc Institute(Brian L. Hie)",
            "team website": "https://github.com/ArcInstitute",
            "affiliation": "",
            "domain": "DNA",
            "venue": "bioRxiv",
            "paperUrl": "https://www.biorxiv.org/content/10.1101/2025.02.18.638918v1",
            "codeUrl": "https://github.com/arcinstitute/evo2",
            "githubStars": "https://img.shields.io/github/stars/arcinstitute/evo2",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        },
        {
            "year": "2025.02",
            "title": "GENERator: A Long-Context Generative Genomic Foundation Model",
            "team": "",
            "team website": "",
            "affiliation": "",
            "domain": "DNA",
            "venue": "arXiv",
            "paperUrl": "https://arxiv.org/abs/2502.07272",
            "codeUrl": "https://github.com/GenerTeam/GENERator",
            "githubStars": "https://img.shields.io/github/stars/GenerTeam/GENERator",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        },
        {
            "year": "2025.02",
            "title": "scGPT-spatial: Continual Pretraining of Single-Cell Foundation Model for Spatial Transcriptomics",
            "team": "Bo Wang",
            "team website": "https://github.com/bowang-lab",
            "affiliation": "",
            "domain": "spatial single cell RNA",
            "venue": "bioRxiv",
            "paperUrl": "https://www.biorxiv.org/content/10.1101/2025.02.05.636714v1",
            "codeUrl": "https://github.com/bowang-lab/scGPT-spatial",
            "githubStars": "https://img.shields.io/github/stars/bowang-lab/scGPT-spatial",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        }
    ],
    "ai-agents": [
        {
            "year": "2025.02",
            "title": "Knowledge Synthesis of Photosynthesis Research Using a Large Language Model",
            "team": "Tae In Ahn",
            "team website": "",
            "affiliation": "",
            "domain": "Photosynthesis research assistant using LLM",
            "abstract": "The development of biological data analysis tools and large language models (LLMs) has opened up new possibilities for utilizing AI in plant science research, with the potential to contribute significantly to knowledge integration and research gap identification. Nonetheless, current LLMs struggle to handle complex biological data and theoretical models in photosynthesis research and often fail to provide accurate scientific contexts. Therefore, this study proposed a photosynthesis research assistant (PRAG) based on OpenAI's GPT-4o with retrieval-augmented generation (RAG) techniques and prompt optimization. Vector databases and an automated feedback loop were used in the prompt optimization process to enhance the accuracy and relevance of the responses to photosynthesis-related queries. PRAG showed an average improvement of 8.7% across five metrics related to scientific writing, with a 25.4% increase in source transparency. Additionally, its scientific depth and domain coverage were comparable to those of photosynthesis research papers. A knowledge graph was used to structure PRAG's responses with papers within and outside the database, which allowed PRAG to match key entities with 63% and 39.5% of the database and test papers, respectively. PRAG can be applied for photosynthesis research and broader plant science domains, paving the way for more in-depth data analysis and predictive capabilities.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/cb217acb0ea521307477a39ec893f135b72ead45",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2502.01059",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.02",
            "title": "Spike sorting AI agent",
            "team": "Jia Liu",
            "team website": "",
            "affiliation": "John A. Paulson School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA",
            "domain": "Spike sorting AI pipeline agent",
            "abstract": "Spike sorting is a fundamental process for decoding neural activity, involving preprocessing, spike detection, feature extraction, clustering, and validation. However, conventional spike sorting methods are highly fragmented, labor-intensive, and heavily reliant on expert manual curation, limiting their scalability and reproducibility. This challenge has become more pressing with advances in neural recording technology, such as high-density Neuropixels for large-scale neural recording or flexible electrodes for long-term stable recording over months to years. The volume and complexity of these datasets make manual curation infeasible, requiring an automated and scalable solution. Here, we introduce SpikeAgent, a multimodal large language model (LLM)-based AI agent that automates and standardizes the entire spike sorting pipeline. Unlike traditional approaches, SpikeAgent integrates multiple LLM backends, coding functions, and established algorithms, autonomously performing spike sorting with reasoning-based decision-making and real-time interaction with intermediate results. It generates interpretable reports, providing transparent justifications for each sorting decision, enhancing transparency and reliability. We benchmarked SpikeAgent against human experts across various neural recording technology, demonstrating its versatility and ability to achieve curation consistency that are equal to, or even higher than human experts. It also drastically reduces the expertise barrier and accelerates the curation and validation time by orders of magnitude. Moreover, it enables automated interpretability of the neural spiking data, which cannot be achieved by any conventional methods. SpikeAgent presents a paradigm shift in processing signals for neuroscience and brain-computer interfaces, while laying the ground for AI agent-augmented science across various domains.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/e44999184842c94e6f976417cbe73431501eac03",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.02.11.637754",
            "reason_for_inclusion": "High quality: Pre-print affiliated with Harvard University, a world-renowned research institution."
        },
        {
            "year": "2025.02",
            "title": "RAPID: Reliable and efficient Automatic generation of submission rePorting checklists with Large language moDels",
            "team": "Lu Zhang",
            "team website": "",
            "affiliation": "Hong Kong Baptist University",
            "domain": "Automated medical reporting checklist generation",
            "abstract": "Importance Medical reporting guidelines are significant in improving the transparency, quality, and integrity of medical research, particularly in randomized clinical trials; adherence to these guidelines supports research interpretability and has direct implications for downstream applications, such as patient treatment. However, with over 600 distinct reporting guidelines, manual assessments are often time-consuming and labor-intensive. Objective To evaluate an automated reporting checklist generation tool using large language models and retrieval augmentation generation technology, called RAPID. Design, Setting, and Participants This study used large language models to design a retrieval augmentation generation architecture and collected published journal articles as training and validation sets to optimize prompts within the framework and comprehensively evaluate the performance of the framework. Medical reporting experiments were collected from 50 randomized controlled trials without the intervention of AI tools and 41 randomized controlled trials with the intervention of AI tools. Main Outcomes and Measures For effective evaluation of the performance of this tool, a classification accuracy metric (Reported/Not Reported) defined as the number of correct judgments divided by all judgments and a content consistent score metric defined as the number of contents retrieved by the tool that are the same as those retrieved by researchers divided by the total number of judgments were calculated. Results The RAPID tool uses the widely used Word document and Portable Document Format as an input file. Fifty published journal articles without the intervention of AI tools and 41 published journal articles with the intervention of AI tools were collected as CONSORT and CONSORT-AI datasets. All of the CONSORT reporting items (37) were included in the tool. RAPID achieved a high average accuracy rate of 92.11% and a content consistency score of 81.14% on the CONSORT dataset. Of the CONSORT-AI reporting items, 11 items related to the intervention of AI tools were included in the tool. RAPID achieved an average accuracy of 83.81% with a content consistency score of 72.51% on the CONSORT-AI dataset. For these two reporting guidelines, a training set of 5 articles was selected from each dataset to refine the prompts used in the tools for CONSORT and CONSORT-AI reporting checklist. The validation set of the remaining articles was used to assess the performance of the RAPID. The RAPID tool used the Word document and Portable Document Format of the articles as input files. A RAPID graphical user interface was built using JavaScript and Vue. Conclusions and Relevance The RAPID tool is designed to assist in the reporting of various types of trials. RAPID has strong scalability, which can be easily adapted to different medical reporting guidelines without transfer learning on a large dataset. RAPID may effectively save time and improve working efficiency for different user groups, for example, 1) simplifying the submission process and improving report quality by verifying manuscript completeness for medical authors; 2) facilitating evaluation of report quality for medical researchers; 3) expediting manuscript distribution for medical editors; and 4) identifying reporting deficiencies and providing deeper insights for review comments for reviewers. Key Points Question Can large language model tools automatically generate medical reporting checklists for manuscripts of different types of clinic trials? Findings An automated reporting checklist generation tool using large language models and retrieval augmentation generation technology, RAPID, was developed. RAPID was fully evaluated on all items across two separate datasets related to the Consolidated Standards of Reporting Trials (CONSORT) and CONSORT-AI reporting guidelines. In the first dataset corresponding to CONSORT, RAPID achieved an average accuracy of 92.11%, while in the second dataset associated with CONSORT - AI, it reached an average accuracy of 83.81%. Additionally, RAPID is highly scalable. It can be easily and smoothly adapted to different medical reporting guidelines without transfer learning on a large dataset. Meaning RAPID can effectively save time and improve working efficiency for different user groups such as medical authors, researchers, editors, and reviewers.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/8ab71d93085aaa5900ad6ec5e7b966829934d95e",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.02.13.638015",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.02",
            "title": "LIDDIA: Language-based Intelligent Drug Discovery Agent",
            "team": "",
            "team website": "",
            "affiliation": "",
            "domain": "Drug Discovery",
            "venue": "arXiv",
            "paperUrl": "https://arxiv.org/abs/2502.13959",
            "codeUrl": "",
            "githubStars": "",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        },
        {
            "year": "2025.02",
            "title": "Towards an AI co-scientist",
            "team": "",
            "team website": "",
            "affiliation": "",
            "domain": "General Scientific Research",
            "venue": "arXiv",
            "paperUrl": "https://arxiv.org/pdf/2502.18864v1",
            "codeUrl": "",
            "githubStars": "",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        }
    ],
    "benchmarks": [
        {
            "year": "2025.02",
            "title": "BioMaze: Benchmarking and Enhancing Large Language Models for Biological Pathway Reasoning",
            "team": "Zhi-Hong Deng",
            "team website": "",
            "affiliation": "",
            "domain": "Biological pathway reasoning benchmark",
            "abstract": "The applications of large language models (LLMs) in various biological domains have been explored recently, but their reasoning ability in complex biological systems, such as pathways, remains underexplored, which is crucial for predicting biological phenomena, formulating hypotheses, and designing experiments. This work explores the potential of LLMs in pathway reasoning. We introduce BioMaze, a dataset with 5.1K complex pathway problems derived from real research, covering various biological contexts including natural dynamic changes, disturbances, additional intervention conditions, and multi-scale research targets. Our evaluation of methods such as CoT and graph-augmented reasoning, shows that LLMs struggle with pathway reasoning, especially in perturbed systems. To address this, we propose PathSeeker, an LLM agent that enhances reasoning through interactive subgraph-based navigation, enabling a more effective approach to handling the complexities of biological systems in a scientifically aligned manner. The dataset and code are available at https://github.com/zhao-ht/BioMaze.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/1456f9a8717ea2987897172a3e855970302cc373",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2502.16660",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.02",
            "title": "The Skin Game: Revolutionizing Standards for AI Dermatology Model Comparison",
            "team": "Dariusz Jemielniak",
            "team website": "",
            "affiliation": "",
            "domain": "Dermatology image classification evaluation framework",
            "abstract": "Deep Learning approaches in dermatological image classification have shown promising results, yet the field faces significant methodological challenges that impede proper evaluation. This paper presents a dual contribution: first, a systematic analysis of current methodological practices in skin disease classification research, revealing substantial inconsistencies in data preparation, augmentation strategies, and performance reporting; second, a comprehensive training and evaluation framework demonstrated through experiments with the DINOv2-Large vision transformer across three benchmark datasets (HAM10000, DermNet, ISIC Atlas). The analysis identifies concerning patterns, including pre-split data augmentation and validation-based reporting, potentially leading to overestimated metrics, while highlighting the lack of unified methodology standards. The experimental results demonstrate DINOv2's performance in skin disease classification, achieving macro-averaged F1-scores of 0.85 (HAM10000), 0.71 (DermNet), and 0.84 (ISIC Atlas). Attention map analysis reveals critical patterns in the model's decision-making, showing sophisticated feature recognition in typical presentations but significant vulnerabilities with atypical cases and composite images. Our findings highlight the need for standardized evaluation protocols and careful implementation strategies in clinical settings. We propose comprehensive methodological recommendations for model development, evaluation, and clinical deployment, emphasizing rigorous data preparation, systematic error analysis, and specialized protocols for different image types. To promote reproducibility, we provide our implementation code through GitHub. This work establishes a foundation for rigorous evaluation standards in dermatological image classification and provides insights for responsible AI implementation in clinical dermatology.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/79dd24bdeaefadf1681d1d68104a02ba78c9c91d",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2502.02500",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.02",
            "title": "Consequences of training data composition for deep learning models in single-cell biology",
            "team": "Lorin Crawford",
            "team website": "",
            "affiliation": "Harvard Medical School",
            "domain": "Training data composition effects in single-cell models",
            "abstract": "Foundation models for single-cell transcriptomics have the potential to augment (or replace) purpose-built tools for a variety of common analyses, especially when data are sparse. Recent work with large language models has shown that training data composition greatly shapes performance; however, to date, single-cell foundation models have ignored this aspect, opting instead to train on the largest possible corpus. We systematically investigate the consequences of training dataset composition on the behavior of deep learning models of single-cell transcriptomics, focusing on human hematopoiesis as a tractable model system and including cells from adult and developing tissues, disease states, and perturbation atlases. We find that (1) these models generalize poorly to unseen cell types, (2) adding malignant cells to a healthy cell training corpus does not necessarily improve modeling of unseen malignant cells, and (3) including an embryonic stem cell differentiation atlas during training improves performance on out-of-distribution tasks. Our results emphasize the importance of diverse training data and suggest strategies to optimize future single-cell foundation models.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/fa6f62ba24bfa8f771c0f01f6a0ecbd81b253088",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.02.19.639127",
            "reason_for_inclusion": "High quality: Pre-print affiliated with Harvard Medical School, a world-renowned research institution."
        }
    ],
    "reviews": [
        {
            "year": "2025.02",
            "title": "Triple Phase Transitions: Understanding the Learning Dynamics of Large Language Models from a Neuroscience Perspective",
            "team": "Yu Takagi",
            "team website": "",
            "affiliation": "",
            "domain": "LLM learning dynamics from a neuroscience perspective",
            "abstract": "Large language models (LLMs) often exhibit abrupt emergent behavior, whereby new abilities arise at certain points during their training. This phenomenon, commonly referred to as a ''phase transition'', remains poorly understood. In this study, we conduct an integrative analysis of such phase transitions by examining three interconnected perspectives: the similarity between LLMs and the human brain, the internal states of LLMs, and downstream task performance. We propose a novel interpretation for the learning dynamics of LLMs that vary in both training data and architecture, revealing that three phase transitions commonly emerge across these models during training: (1) alignment with the entire brain surges as LLMs begin adhering to task instructions Brain Alignment and Instruction Following, (2) unexpectedly, LLMs diverge from the brain during a period in which downstream task accuracy temporarily stagnates Brain Detachment and Stagnation, and (3) alignment with the brain reoccurs as LLMs become capable of solving the downstream tasks Brain Realignment and Consolidation. These findings illuminate the underlying mechanisms of phase transitions in LLMs, while opening new avenues for interdisciplinary research bridging AI and neuroscience.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/49d8af23298ab111494ddc9a79ae6a9d89181217",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2502.20779",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.02",
            "title": "Position: Episodic Memory is the Missing Piece for Long-Term LLM Agents",
            "team": "Mariya Toneva",
            "team website": "",
            "affiliation": "",
            "domain": "Episodic memory framework for long-term LLM agents",
            "abstract": "As Large Language Models (LLMs) evolve from text-completion tools into fully fledged agents operating in dynamic environments, they must address the challenge of continually learning and retaining long-term knowledge. Many biological systems solve these challenges with episodic memory, which supports single-shot learning of instance-specific contexts. Inspired by this, we present an episodic memory framework for LLM agents, centered around five key properties of episodic memory that underlie adaptive and context-sensitive behavior. With various research efforts already partially covering these properties, this position paper argues that now is the right time for an explicit, integrated focus on episodic memory to catalyze the development of long-term agents. To this end, we outline a roadmap that unites several research directions under the goal to support all five properties of episodic memory for more efficient long-term LLM agents.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/f85004321e43370535088042ebac96b958880c5d",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2502.06975",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.02",
            "title": "Microbial Ecology to Ocean Carbon Cycling: From Genomes to Numerical Models",
            "team": "E. Zakem",
            "team website": "",
            "affiliation": "",
            "domain": "Integration of microbial ecology and numerical models for ocean carbon cycling",
            "abstract": "The oceans contain large reservoirs of inorganic and organic carbon and play a critical role in both global carbon cycling and climate. Most of the biogeochemical transformations in the oceans are driven by marine microbes. Thus, molecular processes occurring at the scale of single cells govern global geochemical dynamics, posing a challenge of scales. Understanding the processes controlling ocean carbon cycling from the cellular to the global scale requires the integration of multiple disciplines including microbiology, ecology, biogeochemistry, and computational fields such as numerical models and bioinformatics. A shared language and foundational knowledge will facilitate these interactions. This review provides the state of knowledge on the role marine microbes play in large-scale ocean carbon cycling through the lens of observational oceanography and biogeochemical models. We conclude by outlining ways in which the field can bridge the gap between -omics datasets and ocean models to understand ocean carbon cycling across scales.\n\n \n \u25aa\n -Omic approaches are providing increasingly quantitative insight into the biogeochemical functions of marine microbial ecosystems.\n \n \n \u25aa\n Numerical models provide a tool for studying global carbon cycling by scaling from the microscale to the global scale.\n \n \n \u25aa\n The integration of -omics and numerical modeling generates new understanding of how microbial metabolisms and community dynamics set nutrient fluxes in the ocean.\n \n \n",
            "venue": "Annual Review of Earth and Planetary Sciences",
            "paperUrl": "https://www.semanticscholar.org/paper/dc5335e5ec2bf80abda630ada4eb431a173ddec4",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1146/annurev-earth-040523-020630",
            "reason_for_inclusion": "High quality: Published in Annual Review of Earth and Planetary Sciences, a top-tier journal."
        }
    ],
    "databases": [
        {
            "year": "2025.02",
            "title": "Literature-scaled immunological gene set annotation using AI-powered immune cell knowledge graph (ICKG)",
            "team": "Ken Chen",
            "team website": "",
            "affiliation": "MD Anderson Cancer Center",
            "domain": "Immune cell knowledge graph for gene set annotation",
            "abstract": "",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/b51970fcc636348932f171cf220d810b5a873ba0",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.02.19.639172",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.02",
            "title": "scBaseCount: an AI agent-curated, uniformly processed, and continually expanding single cell data repository",
            "team": "Arc Institute(Yusuf H. Roohani)",
            "team website": "https://github.com/ArcInstitute",
            "affiliation": "",
            "domain": "preprocess scRNA data",
            "venue": "bioRxiv",
            "paperUrl": "https://www.biorxiv.org/content/10.1101/2025.02.27.640494v2",
            "codeUrl": "https://github.com/ArcInstitute/SRAgent",
            "githubStars": "https://img.shields.io/github/stars/ArcInstitute/SRAgent",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        },
        {
            "year": "2025.02",
            "title": "Tahoe-100M: A Giga-Scale Single-Cell Perturbation Atlas for Context-Dependent Gene Function and Cellular Modeling",
            "team": "tahoebio(but in arc's repository)",
            "team website": "https://github.com/ArcInstitute",
            "affiliation": "",
            "domain": "Drug perturbation scRNA",
            "venue": "bioRxiv",
            "paperUrl": "https://www.biorxiv.org/content/10.1101/2025.02.20.639398v3",
            "codeUrl": "https://github.com/ArcInstitute/arc-virtual-cell-atlas",
            "githubStars": "https://img.shields.io/github/stars/ArcInstitute/arc-virtual-cell-atlas",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        }
    ]
}