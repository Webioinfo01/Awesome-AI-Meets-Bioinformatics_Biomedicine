{
    "benchmarks": [
        {
            "year": "2025.01",
            "title": "CARDBiomedBench: A Benchmark for Evaluating Large Language Model Performance in Biomedical Research",
            "team": "F. Faghri",
            "team website": "",
            "affiliation": "Center for Alzheimer's and Related Dementias, National Institute on Aging, National Institutes of Health, Bethesda, MD, 20892, USA; DataTecnica, Washington, ",
            "domain": "LLM evaluation in neurodegenerative disease research",
            "abstract": "Backgrounds Biomedical research requires sophisticated understanding and reasoning across multiple specializations. While large language models (LLMs) show promise in scientific applications, their capability to safely and accurately support complex biomedical research remains uncertain. Methods We present CARDBiomedBench, a novel question-and-answer benchmark for evaluating LLMs in biomedical research. For our pilot implementation, we focus on neurodegenerative diseases (NDDs), a domain requiring integration of genetic, molecular, and clinical knowledge. The benchmark combines expert-annotated question-answer (Q/A) pairs with semi-automated data augmentation, drawing from authoritative public resources including drug development data, genome-wide association studies (GWAS), and Summary-data based Mendelian Randomization (SMR) analyses. We evaluated seven private and open-source LLMs across ten biological categories and nine reasoning skills, using novel metrics to assess both response quality and safety. Results Our benchmark comprises over 68,000 Q/A pairs, enabling robust evaluation of LLM performance. Current state-of-the-art models show significant limitations: models like Claude-3.5-Sonnet demonstrates excessive caution (Response Quality Rate: 25% [95% CI: 25% \u00b1 1], Safety Rate: 76% \u00b1 1), while others like ChatGPT-4o exhibits both poor accuracy and unsafe behavior (Response Quality Rate: 37% \u00b1 1, Safety Rate: 31% \u00b1 1). These findings reveal fundamental gaps in LLMs\u2019 ability to handle complex biomedical information. Conclusion CARDBiomedBench establishes a rigorous standard for assessing LLM capabilities in biomedical research. Our pilot evaluation in the NDD domain reveals critical limitations in current models\u2019 ability to safely and accurately process complex scientific information. Future iterations will expand to other biomedical domains, supporting the development of more reliable AI systems for accelerating scientific discovery.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/8b9312c65220e7ef9c5edfc5b3b9f8bb259e1444",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.01.15.633272",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.01",
            "title": "Large Language Models Think Too Fast To Explore Effectively",
            "team": "Robert C. Wilson",
            "team website": "",
            "affiliation": "",
            "domain": "Exploration capabilities of LLMs in open-ended tasks",
            "abstract": "Large Language Models (LLMs) have emerged with many intellectual capacities. While numerous benchmarks assess their intelligence, limited attention has been given to their ability to explore--an essential capacity for discovering new information and adapting to novel environments in both natural and artificial systems. The extent to which LLMs can effectively explore, particularly in open-ended tasks, remains unclear. This study investigates whether LLMs can surpass humans in exploration during an open-ended task, using Little Alchemy 2 as a paradigm, where agents combine elements to discover new ones. Results show most LLMs underperform compared to humans, except for the o1 model, with traditional LLMs relying primarily on uncertainty-driven strategies, unlike humans who balance uncertainty and empowerment. Results indicate that traditional reasoning-focused LLMs, such as GPT-4o, exhibit a significantly faster and less detailed reasoning process, limiting their exploratory performance. In contrast, the DeepSeek reasoning model demonstrates prolonged, iterative thought processes marked by repetitive analysis of combinations and past trials, reflecting a more thorough and human-like exploration strategy. Representational analysis of the models with Sparse Autoencoders (SAE) revealed that uncertainty and choices are represented at earlier transformer blocks, while empowerment values are processed later, causing LLMs to think too fast and make premature decisions, hindering effective exploration. These findings shed light on the limitations of LLM exploration and suggest directions for improving their adaptability.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/7d4202a3e3801d6304e0e2463c49d033b37da77d",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2501.18009",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.01",
            "title": "Sequence Modeling Is Not Evolutionary Reasoning",
            "team": "M. Zitnik",
            "team website": "",
            "affiliation": "Harvard Medical School",
            "domain": "Evolutionary reasoning benchmark for protein LLMs",
            "abstract": "Protein language models (PLMs) are commonly assumed to capture evolutionary information by training on large protein sequence datasets. However, it remains unclear whether PLMs can reason about evolution\u2014that is, infer evolutionary relationships between protein sequences. To test this capability, we introduce a benchmark for evolutionary reasoning and find that existing PLMs consistently fail to recover phylogenetic structure, despite strong performance on standard tasks such as masked token prediction and contact prediction. To address this limitation, we present Phyla. Phylaintroduces a hybrid state-space and transformer architecture that jointly process multiple sequences and is trained using a tree-based objective over 3,000 phylogenies spanning diverse protein families. Phylaachieves state-of-the-art performance in evolutionary reasoning, outper-forming the next-best model by 13% on tree reconstruction and 10% on taxonomic clustering. Beyond synthetic benchmarks, Phylaapplies to real-world settings: it reconstructs biologically accurate branches of the tree of life and infers whole-genome evolutionary relationships from Mycobacterium tuberculosis genomes. These findings suggest that evolutionary reasoning is not an emergent property of large-scale sequence modeling. Instead, Phylashows that models trained with phylogenetic supervision can reason about evolution more effectively, offering a biologically grounded path toward evolutionary foundation models.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/f62b34cfa37bc9066affe185da5349f4c9ef9fb0",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.01.17.633626",
            "reason_for_inclusion": "Included to meet target filter limit."
        }
    ],
    "reviews": [
        {
            "year": "2025.01",
            "title": "Survey and Improvement Strategies for Gene Prioritization with Large Language Models",
            "team": "Xia Hu",
            "team website": "",
            "affiliation": "",
            "domain": "LLM-based gene prioritization",
            "abstract": "\n \n \n Rare diseases remain difficult to diagnose due to limited patient data and genetic diversity, with many cases remaining undiagnosed despite advances in variant prioritization tools. While large language models have shown promise in medical applications, their optimal application for trustworthy and accurate gene prioritization downstream of modern prioritization tools has not been systematically evaluated.\n \n \n \n We benchmarked various language models for gene prioritization using multi-agent and Human Phenotype Ontology classification approaches to categorize patient cases by phenotype-based solvability levels. To address language model limitations in ranking large gene sets, we implemented a divide-and-conquer strategy with mini-batching and token limiting for improved efficiency. GPT-4 outperformed other language models across all patient datasets, demonstrating superior accuracy in ranking causal genes. Multi-agent and Human Phenotype Ontology classification approaches effectively distinguished between confidently-solved and challenging cases. However, we observed bias towards well-studied genes and input order sensitivity as notable language model limitations. Our divide-and-conquer strategy enhanced accuracy, overcoming positional and gene frequency biases in literature. This framework optimized the overall process for identifying disease-causal genes compared to baseline evaluation, better enabling targeted diagnostic and therapeutic interventions and streamlining diagnosis of rare genetic disorders.\n \n \n \n Software and additional material is available at: https://github.com/LiuzLab/GPT-Diagnosis\n",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/7ca21dec02c418f010d6b95de3bde7bb6ac69c66",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2501.18794",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.01",
            "title": "Computational Protein Science in the Era of Large Language Models (LLMs)",
            "team": "Qing Li",
            "team website": "",
            "affiliation": "",
            "domain": "Computational protein science with LLMs",
            "abstract": "Considering the significance of proteins, computational protein science has always been a critical scientific field, dedicated to revealing knowledge and developing applications within the protein sequence-structure-function paradigm. In the last few decades, Artificial Intelligence (AI) has made significant impacts in computational protein science, leading to notable successes in specific protein modeling tasks. However, those previous AI models still meet limitations, such as the difficulty in comprehending the semantics of protein sequences, and the inability to generalize across a wide range of protein modeling tasks. Recently, LLMs have emerged as a milestone in AI due to their unprecedented language processing&generalization capability. They can promote comprehensive progress in fields rather than solving individual tasks. As a result, researchers have actively introduced LLM techniques in computational protein science, developing protein Language Models (pLMs) that skillfully grasp the foundational knowledge of proteins and can be effectively generalized to solve a diversity of sequence-structure-function reasoning problems. While witnessing prosperous developments, it's necessary to present a systematic overview of computational protein science empowered by LLM techniques. First, we summarize existing pLMs into categories based on their mastered protein knowledge, i.e., underlying sequence patterns, explicit structural and functional information, and external scientific languages. Second, we introduce the utilization and adaptation of pLMs, highlighting their remarkable achievements in promoting protein structure prediction, protein function prediction, and protein design studies. Then, we describe the practical application of pLMs in antibody design, enzyme design, and drug discovery. Finally, we specifically discuss the promising future directions in this fast-growing field.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/0322d6eef1567b8b6ce3998d03f955082f9a87b6",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2501.10282",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.01",
            "title": "Foundation models in bioinformatics",
            "team": "Jianxin Wang",
            "team website": "",
            "affiliation": "",
            "domain": "Bioinformatics foundation models overview",
            "abstract": "ABSTRACT With the adoption of foundation models (FMs), artificial intelligence (AI) has become increasingly significant in bioinformatics and has successfully addressed many historical challenges, such as pre-training frameworks, model evaluation and interpretability. FMs demonstrate notable proficiency in managing large-scale, unlabeled datasets, because experimental procedures are costly and labor intensive. In various downstream tasks, FMs have consistently achieved noteworthy results, demonstrating high levels of accuracy in representing biological entities. A new era in computational biology has been ushered in by the application of FMs, focusing on both general and specific biological issues. In this review, we introduce recent advancements in bioinformatics FMs employed in a variety of downstream tasks, including genomics, transcriptomics, proteomics, drug discovery and single-cell analysis. Our aim is to assist scientists in selecting appropriate FMs in bioinformatics, according to four model types: language FMs, vision FMs, graph FMs and multimodal FMs. In addition to understanding molecular landscapes, AI technology can establish the theoretical and practical foundation for continued innovation in molecular biology.",
            "venue": "National Science Review",
            "paperUrl": "https://www.semanticscholar.org/paper/3f21f2fadc60b7f627b5154a9944ec22d28c2678",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1093/nsr/nwaf028",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.01",
            "title": "AI Methods for Antimicrobial Peptides: Progress and Challenges",
            "team": "C\u00e9sar de la Fuente-Nunez",
            "team website": "",
            "affiliation": "",
            "domain": "AI methods for antimicrobial peptide design",
            "abstract": "Antimicrobial peptides (AMPs) are promising candidates to combat multidrug\u2010resistant pathogens. However, the high cost of extensive wet\u2010lab screening has made AI methods for identifying and designing AMPs increasingly important, with machine learning (ML) techniques playing a crucial role. AI approaches have recently revolutionised this field by accelerating the discovery of new peptides with anti\u2010infective activity, particularly in preclinical mouse models. Initially, classical ML approaches dominated the field, but recently there has been a shift towards deep learning (DL) models. Despite significant contributions, existing reviews have not thoroughly explored the potential of large language models (LLMs), graph neural networks (GNNs) and structure\u2010guided AMP discovery and design. This review aims to fill that gap by providing a comprehensive overview of the latest advancements, challenges and opportunities in using AI methods, with a particular emphasis on LLMs, GNNs and structure\u2010guided design. We discuss the limitations of current approaches and highlight the most relevant topics to address in the coming years for AMP discovery and design.",
            "venue": "Microbial Biotechnology",
            "paperUrl": "https://www.semanticscholar.org/paper/9c310642e1a07abeab7c6a8216ec60328feb74a2",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1111/1751-7915.70072",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.01",
            "title": "Artificial intelligence driven innovations in biochemistry: A review of emerging research frontiers",
            "team": "M. A. Lateef Junaid",
            "team website": "",
            "affiliation": "",
            "domain": "AI innovations in biochemistry",
            "abstract": "Artificial intelligence (AI) has become a powerful tool in biochemistry, greatly enhancing research capabilities by enabling the analysis of complex datasets, predicting molecular interactions, and accelerating drug discovery. As AI continues to evolve, its applications in biochemistry are poised to expand, revolutionizing both theoretical and applied research. This review explores current and potential AI applications in biochemistry, with a focus on data analysis, molecular modeling, enzyme engineering, and metabolic pathway studies. Key AI techniques\u2014such as machine learning algorithms, natural language processing, and AI-based molecular modeling\u2014are discussed. The review also highlights emerging research areas benefiting from AI, including personalized medicine and synthetic biology. The methodology involves an extensive analysis of existing literature, particularly peer-reviewed studies on AI applications in biochemistry. AI-driven tools like AlphaFold, which have significantly advanced protein structure prediction, are evaluated alongside AI\u2019s role in expediting drug discovery. The review also addresses challenges, such as data quality, model interpretability, and ethical considerations. Results indicate that AI has expanded the scope of biochemical research by facilitating large-scale data analysis, enhancing molecular simulations, and opening new avenues of inquiry. However, challenges remain, particularly in data handling and ethical concerns. In conclusion, AI is transforming biochemistry by driving innovation and expanding research possibilities. Future advancements in AI algorithms, interdisciplinary collaboration, and integration with automated techniques will be crucial to fully unlocking AI\u2019s potential in advancing biochemical research.",
            "venue": "Biomolecules and Biomedicine",
            "paperUrl": "https://www.semanticscholar.org/paper/fa06241dfa98d42974532dd314b87d14ad5dc33f",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.17305/bb.2024.11537",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.01",
            "title": "Artificial Intelligence Tools Addressing Challenges of Cancer Progression Due to Antimicrobial Resistance in Pathogenic Biofilm Systems",
            "team": "Abhijit G. Banerjee",
            "team website": "",
            "affiliation": "",
            "domain": "AI tools for antimicrobial resistance in cancer biofilms",
            "abstract": "Infections, inflammation, and progression of multifactorial diseases are found to be integratively linked, including most Cancers. Dysfunctional microbiomes are also associated with several cancers in their tumor microenvironments. Antimicrobial peptides (AMPs) are short, positively charged peptides found in a diverse range of species, including bacteria and humans. As host defense peptides, they can destroy pathogenic infections, particularly those that are multidrug resistant. AMPs have raised hopes in the biomedical and pharmaceutical industries as fresh non-antibiotic strategies for combating infectious diseases. However, in vitro\u00a0and in vivo\u00a0verification of AMPs is problematic and may miss new antimicrobial drugs. Creating computational methods for quick and precise identification of AMPs and their functional forms is critical for developing new and more effective antimicrobial drugs. Machine learning techniques were recently discovered effective at mining, predicting, and producing efficient antimicrobial peptides from a large AMP database. We reviewed 76 articles, after following literature search rubrics to come to the following conclusions. Distance metric-constant K-based nearest neighbor algorithms (KNN), hidden Markov models (HMMs), support vector machine models (SVMs), random forest models (RFs), decision tree models, and deep neural network (DNN)-based models are some of the most popular AI tools for detecting antimicrobial activity in peptide sequence-derived structure and function. Knowledge graphs can further assist in identifying hub genes and antimicrobial peptides that target and block quorum sensing (QS) signals within the microbial networks. In conclusion, we state that currently no single AI method has been found appropriate for AMP discovery and accurately capable of predicting high-efficacy AMPs. Our current literature review and analysis identify cutting-edge algorithms or innovations that might be included in hybrid machine-learning approaches for the most effective AMP identification, creation, and prediction. Non-peptide, natural molecule-based approaches to AMR reduction are also being studied for development, with natural peptide scaffolds serving as the foundation.",
            "venue": "Artificial Intelligence Evolution",
            "paperUrl": "https://www.semanticscholar.org/paper/a86fd4458cbbe7f1ea491d93c1b5ec31da8d272d",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.37256/aie.6120255553",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.01",
            "title": "Learning the language of life with AI.",
            "team": "E. Topol",
            "team website": "",
            "affiliation": "",
            "domain": "Multiomic foundation models for biomolecule prediction",
            "abstract": "In 2021, a year before ChatGPT took the world by storm amid the excitement about generative artificial intelligence (AI), AlphaFold 2 cracked the 50-year-old protein-folding problem, predicting three-dimensional (3D) structures for more than 200 million proteins from their amino acid sequences. This accomplishment was a precursor to an unprecedented burgeoning of large language models (LLMs) in the life sciences. That was just the beginning. In recent months, we have moved into a hyperaccelerated phase of new foundation models, pretrained on massive datasets, with the ability to perform a wide range of tasks that are helping us understand the structure, biology, evolution, and design of proteins, RNA, DNA, and ligands, as well as their biomolecular interactions. Unlike multimodal LLMs such as GPT-4, Gemini, and Claude, which process text, audio, and images, these large language of life models (LLLMs) are multiomic. That is to say, they are not only multimodal but pertain to different layers of molecular biology. For example, Evo, a foundation model trained on 2.7 million diverse phage and prokaryotic genomes (equivalent to about 300 billion DNA nucleotides), predicts the impact of variants in DNA, RNA, or proteins on structure and function, as well as how essential genes are to cell function, and can generate new DNA sequences.",
            "venue": "Science",
            "paperUrl": "https://www.semanticscholar.org/paper/864031c9cc2195153f6fc08fed9d67131ddee8c4",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1126/science.adv4414",
            "reason_for_inclusion": "High quality: Published in Science, a top-tier journal."
        }
    ],
    "foundation-models": [
        {
            "year": "2025.01",
            "title": "Improving functional protein generation via foundation model-derived latent space likelihood optimization",
            "team": "C\u00e9sar de la Fuente-Nunez",
            "team website": "",
            "affiliation": "University of Pennsylvania",
            "domain": "Generative protein design via PLM latent space optimization",
            "abstract": "A variety of deep generative models have been adopted to perform de novo functional protein generation. Compared to 3D protein design, sequence-based generation methods, which aim to generate amino acid sequences with desired functions, remain a major approach for functional protein generation due to the abundance and quality of protein sequence data, as well as the relatively low modeling complexity for training. Although these models are typically trained to match protein sequences from the training data, exact matching of every amino acid is not always essential. Certain amino acid changes (e.g., mismatches, insertions, and deletions) may not necessarily lead to functional changes. This suggests that maximizing the training data likelihood beyond the amino acid sequence space could yield better generative models. Pre-trained protein large language models (PLMs) like ESM2 can encode protein sequences into a latent space, potentially serving as functional validators. We propose training functional protein sequence generative models by simultaneously optimizing the likelihood of training data in both the amino acid sequence space and the latent space derived from a PLM. This training scheme can also be viewed as a knowledge distillation approach that dynamically re-weights samples during training. We applied our method to train GPT- like models (i.e., autoregressive transformers) for antimicrobial peptide (AMP) and malate dehydrogenase (MDH) generation tasks. Computational experiments confirmed that our method outperformed various deep generative models (e.g., generative adversarial net, variational autoencoder, and GPT model without the proposed training strategy) on these tasks, demonstrating the effectiveness of our multi-likelihood optimization strategy.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/98be9134fce5ba8889ea6de518b814c9482ecd8e",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.01.07.631724",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.01",
            "title": "Unveiling the Evolution of Antimicrobial Peptides in Gut Microbes via Foundation Model-Powered Framework",
            "team": "Jinfang Zheng",
            "team website": "",
            "affiliation": "Zhejiang Lab",
            "domain": "Antimicrobial peptide discovery from gut microbes",
            "abstract": "Antimicrobial resistance poses a growing threat to public health, emphasizing the urgent need for novel therapeutic strategies. Antimicrobial peptides (AMPs), short peptide sequences with diverse mechanisms of action, offer a promising alternative due to their broad-spectrum activity against pathogens. Recent advances in protein language models (PLMs) have revolutionized protein structure prediction and functional annotation, highlighting their potential for AMP discovery and therapeutic development. In this context, we present AMP-SEMiner (Antimicrobial Peptide Structural Evolution Miner), an AI-driven framework designed to identify AMPs from metagenome-assembled genomes (MAGs). By integrating PLMs, structural clustering and evolutionary analysis into the framework, AMP-SEMiner can identify AMPs encoded by small open reading frames (smORFs) and encrypted peptides (EPs), significantly expanding the discovery space. Using this approach, we identified 1,670,600 AMP candidates from diverse habitats. Experimental validation of 29 candidates revealed antimicrobial activity in 18, with 13 surpassing antibiotics in effectiveness. Further analysis of AMPs from human gut microbiomes demonstrated both conserved and adaptive evolutionary strategies, ensuring their functional efficacy in the dynamic gut environment. These findings position AMP-SEMiner as a powerful tool for the discovery and characterization of novel AMPs, with significant potential to drive the development of new antimicrobial therapies.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/2fc9811c567186a15873eb8600df36b27f40c088",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.01.13.632881",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.01",
            "title": "Knowledge Hierarchy Guided Biological-Medical Dataset Distillation for Domain LLM Training",
            "team": "Meng Xiao",
            "team website": "",
            "affiliation": "",
            "domain": "Biomedical dataset distillation for LLM training",
            "abstract": "The rapid advancement of large language models (LLMs) in biological-medical applications has highlighted a gap between their potential and the limited scale and often low quality of available open-source annotated textual datasets. In addition, the inherent complexity of the biomedical knowledge hierarchy significantly hampers efforts to bridge this gap.Can LLMs themselves play a pivotal role in overcoming this limitation? Motivated by this question, we investigate this challenge in the present study.We propose a framework that automates the distillation of high-quality textual training data from the extensive scientific literature. Our approach self-evaluates and generates questions that are more closely aligned with the biomedical domain, guided by the biomedical knowledge hierarchy through medical subject headings (MeSH). This comprehensive framework establishes an automated workflow, thereby eliminating the need for manual intervention. Furthermore, we conducted comprehensive experiments to evaluate the impact of our framework-generated data on downstream language models of varying sizes. Our approach substantially improves question-answering tasks compared to pre-trained models from the life sciences domain and powerful close-source models represented by GPT-4. Notably, the generated AI-Ready dataset enabled the Llama3-70B base model to outperform GPT-4 using MedPrompt with multiple times the number of parameters. Detailed case studies and ablation experiments underscore the significance of each component within our framework",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/8d6ab0e57aa1f7d20e680f3306a9e098a9b3a286",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2501.15108",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.01",
            "title": "A foundation model of transcription across human cell types",
            "team": "",
            "team website": "",
            "affiliation": "",
            "domain": "transcriptional regulation(ATAC-seq)",
            "venue": "Nature",
            "paperUrl": "https://www.nature.com/articles/s41586-024-08391-z",
            "codeUrl": "https://github.com/GET-Foundation",
            "githubStars": "https://img.shields.io/github/stars/GET-Foundation/get_model",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        },
        {
            "year": "2025.01",
            "title": "GENA-LM: a new DNA language model for long sequences",
            "team": "",
            "team website": "",
            "affiliation": "",
            "domain": "DNA",
            "venue": "Nucleic Acids Research",
            "paperUrl": "https://academic.oup.com/nar/article/53/2/gkae1310/7954523",
            "codeUrl": "https://github.com/AIRI-Institute/GENA_LM",
            "githubStars": "https://img.shields.io/github/stars/AIRI-Institute/GENA_LM",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        },
        {
            "year": "2025.01",
            "title": "Function-Guided Conditional Generation Using Protein Language Models with Adapters",
            "team": "Salesforce Research( Ali Madani)",
            "team website": "https://github.com/salesforce",
            "affiliation": "",
            "domain": "Protein",
            "venue": "arXiv",
            "paperUrl": "https://arxiv.org/abs/2410.03634",
            "codeUrl": "https://github.com/Profluent-Internships/ProCALM",
            "githubStars": "https://img.shields.io/github/stars/Profluent-Internships/ProCALM",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        },
        {
            "year": "2025.01",
            "title": "Simulating 500 million years of evolution with a language model",
            "team": "EvolutionaryScale(Alexander Rives)",
            "team website": "https://github.com/evolutionaryscale",
            "affiliation": "",
            "domain": "Protein",
            "venue": "Science",
            "paperUrl": "https://www.science.org/doi/10.1126/science.ads0018",
            "codeUrl": "https://github.com/evolutionaryscale/esm",
            "githubStars": "https://img.shields.io/github/stars/evolutionaryscale/esm",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        },
        {
            "year": "2025.01",
            "title": "Predicting cell morphological responses to perturbations using generative modeling",
            "team": "Fabian J. Theis, Mohammad Lotfollahi",
            "team website": "https://github.com/theislab",
            "affiliation": "",
            "domain": "phenotype morphological responses to perturbation",
            "venue": "Nature Communications",
            "paperUrl": "https://www.nature.com/articles/s41467-024-55707-8",
            "codeUrl": "https://github.com/theislab/IMPA",
            "githubStars": "https://img.shields.io/github/stars/theislab/IMPA",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        }
    ],
    "ai-agents": [
        {
            "year": "2025.01",
            "title": "Extracting Knowledge from Scientific Texts on Patient-Derived Cancer Models Using Large Language Models: Algorithm Development and Validation",
            "team": "G. Savova",
            "team website": "",
            "affiliation": "Boston Children's Hospital, Harvard Medical School",
            "domain": "LLM-based entity extraction for patient-derived cancer models",
            "abstract": "Patient-derived cancer models (PDCMs) have emerged as indispensable tools in both cancer research and preclinical studies. The number of publications on PDCMs increased significantly in the last decade. Developments in Artificial Intelligence (AI), particularly Large Language Models (LLMs), hold promise for extracting knowledge from scientific texts at scale. This study investigates the use of LLM-based systems for automatically extracting PDCM-related entities from scientific texts. We evaluated two approaches: direct prompting and soft prompting using LLMs. For direct prompting, we manually create prompts to guide the LLMs to output PDCM-related entities from texts. The prompt consists of an instruction, definitions of entity types, gold examples and a query. We automatically train soft prompts \u2013 a novel line of research in this domain - as continuous vectors using machine learning approaches. Our experiments utilized state-of-the-art LLMs \u2013 proprietary GPT4-o and a series of open LLaMA3 family models. In our experiments, GPT4-o with direct prompts maintained competitive results. Our results demonstrate that soft prompting can effectively enhance the capabilities of smaller open LLMs, achieving results comparable to proprietary models. These findings highlight the potential of LLMs in domain-specific text extraction tasks and emphasize the importance of tailoring approaches to the task and model characteristics.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/4ea31174978b289183898b4cafd1432d9ddd0349",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.01.28.634527",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.01",
            "title": "BioMaster: Multi-agent System for Automated Bioinformatics Analysis Workflow",
            "team": "",
            "team website": "",
            "affiliation": "",
            "domain": "Multi-omics Pipelines",
            "venue": "bioRxiv",
            "paperUrl": "https://www.biorxiv.org/content/10.1101/2025.01.23.634608v1",
            "codeUrl": "https://github.com/ai4nucleome/BioMaster",
            "githubStars": "https://img.shields.io/github/stars/ai4nucleome/BioMaster",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        },
        {
            "year": "2025.01",
            "title": "InstructCell: A Multi-Modal AI Copilot for Single-Cell Analysis with Instruction Following",
            "team": "",
            "team website": "",
            "affiliation": "",
            "domain": "single cell RNA",
            "venue": "arXiv",
            "paperUrl": "https://arxiv.org/abs/2501.08187",
            "codeUrl": "https://github.com/zjunlp/InstructCell",
            "githubStars": "https://img.shields.io/github/stars/zjunlp/InstructCell",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        },
        {
            "year": "2025.01",
            "title": "BioAgents: Democratizing Bioinformatics Analysis with Multi-Agent Systems",
            "team": "Microsoft Research(Venkat S. Malladi)",
            "team website": "https://github.com/microsoft",
            "affiliation": "",
            "domain": "Multi-omics Pipelines",
            "venue": "arXiv",
            "paperUrl": "https://arxiv.org/abs/2501.06314",
            "codeUrl": "",
            "githubStars": "",
            "doi": "",
            "reason_for_inclusion": "",
            "abstract": ""
        }
    ]
}