{
    "ai-agents": [
        {
            "year": "2025.05",
            "title": "CellTypeAgent: Trustworthy cell type annotation with Large Language Models",
            "team": "Yunjian Li",
            "team website": "",
            "affiliation": "",
            "domain": "LLM agent for cell type annotation in single-cell data",
            "abstract": "Cell type annotation is a critical yet laborious step in single-cell RNA sequencing analysis. We present a trustworthy large language model (LLM)-agent, CellTypeAgent, which integrates LLMs with verification from relevant databases. CellTypeAgent achieves higher accuracy than existing methods while mitigating hallucinations. We evaluated CellTypeAgent across nine real datasets involving 303 cell types from 36 tissues. This combined approach holds promise for more efficient and reliable cell type annotation.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/40e125e1b882b278d14d7f86617a4381084fa69a",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2505.08844",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2025.05",
            "title": "ChatMolData: A Multimodal Agent for Automatic Molecular Data Processing",
            "team": "Xiaohui Yu",
            "team website": "",
            "affiliation": "",
            "domain": "Multimodal LLM-agent for automatic molecular data processing",
            "abstract": "In recent years, the development of large language models (LLMs) has revolutionized various fields of natural science. However, their application in dealing with various molecular data remains constrained due to the reliance on single\u2010modality inputs and outputs. ChatMolData, a novel LLM\u2010based multimodal agent designed to handle diverse molecular data forms, including molecular databases, images, structure\u2010specific files, and unstructured and structured documents, is introduced. ChatMolData integrates the capabilities of LLMs (e.g., GPT\u20104 and GPT\u20103.5) with the robust toolset that supports data retrieval, structuring, prediction, visualization, and search tasks. The agent employs a systematic cycle of reasoning and action to efficiently process complex tasks in molecular science. The evaluation demonstrates that ChatMolData achieves over 90% accuracy for 128 diverse tasks, effectively bridging the gap between experimenters and computational tools. Moreover, it is anticipated that the multimodal\u2010agent strategy provides a pathway to expand data size and improve data accessibility, ultimately promoting molecular research and innovation.",
            "venue": "Advanced Intelligent Systems",
            "paperUrl": "https://www.semanticscholar.org/paper/1fd6efbd486e07872b17bf8b08ab68c5a60716c0",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1002/aisy.202401089",
            "reason_for_inclusion": "High quality: Published in Advanced Intelligent Systems, a reputable journal."
        },
        {
            "year": "2025.05",
            "title": "PlantGPT: An Arabidopsis-Based Intelligent Agent that Answers Questions about Plant Functional Genomics.",
            "team": "Qinlong Zhu",
            "team website": "",
            "affiliation": "",
            "domain": "PlantGPT: LLM agent for plant functional genomics question answering",
            "abstract": "Research into plant gene function is crucial for developing strategies to increase crop yields. The recent introduction of large language models (LLMs) offers a means to aggregate large amounts of data into a queryable format, but the output can contain inaccurate or false claims known as hallucinations. To minimize such hallucinations and produce high-quality knowledge-based outputs, the abstracts of over 60\u00a0000 plant research articles are compiled into a Chroma database for retrieval-augmented generation (RAG). Then linguistic data are used from 13\u00a0993 Arabidopsis (Arabidopsis thaliana) phenotypes and 23\u00a0323 gene functions to fine-tune the LLM Llama3-8B, producing PlantGPT, a virtual expert in Arabidopsis phenotype-gene research. By evaluating answers to test questions, it is demonstrated that PlantGPT outperforms general LLMs in answering specialized questions. The findings provide a blueprint for functional genomics research in food crops and demonstrate the potential for developing LLMs for plant research modalities. To provide broader access and facilitate adoption, the online tool http://www.plantgpt.icu is developed, which will allow researchers to use PlantGPT in their scientific investigations.",
            "venue": "Advanced science",
            "paperUrl": "https://www.semanticscholar.org/paper/b0b726a254ede59afe4ab6635fb23c916ceacb94",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1002/advs.202503926",
            "reason_for_inclusion": "High quality: Published in Advanced Science, a top-tier journal."
        },
        {
            "year": "2025.05",
            "title": "DrugPilot: LLM-based Parameterized Reasoning Agent for Drug Discovery",
            "team": "Wenbin Hu",
            "team website": "",
            "affiliation": "",
            "domain": "LLM-based agent for parameterized reasoning in drug discovery",
            "abstract": "In the field of AI4Science, large-scale language models (LLMs) show great potential to parse complex scientific semantics, integrate cross-disciplinary knowledge, and assist critical task research. However, in the field of drug discovery, despite the optimization through professional data pre-training, context window expansion, and internet search, the existing LLMs are still facing challenges such as massive multi-modal and heterogeneous data processing, domain knowledge dynamic updating delay, and insufficient confidence in predicting the results of complex computational tasks. To address these challenges, we propose the DrugPilot, an LLM-based agent with parameterized reasoning for drug discovery. DrugPilot addresses key limitations of traditional end-to-end LLM prediction approaches through its parametric inference architecture. This agent system supports major phases of the drug discovery pipeline, facilitating automated planning and execution of multi-stage research tasks. To address the critical challenge of multi-modal drug data analysis (incorporating both public datasets and user-submitted data), we developed an interactive parameterized memory pool. This innovative component standardizes real-world drug data into parametric representations, simultaneously enabling efficient knowledge retrieval in multi-turn dialogue while mitigating the information loss inherent in text-based data transmission. Additionally, we created a drug instruct dataset across 8 essential drug discovery tasks for model fine-tuning and evaluation. Based on the Berkeley function calling evaluation framework, DrugPilot demonstrated the most advanced tool calling capabilities on our drug discovery tool instruction dataset, outperforming existing agents (e.g., ReAct, LoT). Specifically, it achieves task completion rates of 98.0%, 93.5%, and 64.0% on simple, multiple, and multi-turn tasks, respectively.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/a51b28d8fcf17077a038fe775117865731f9c98d",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2505.13940",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2025.05",
            "title": "Automatic biomarker discovery and enrichment with BRAD",
            "team": "I. Rajapakse",
            "team website": "",
            "affiliation": "",
            "domain": "LLM agent for automatic biomarker discovery and enrichment (BRAD)",
            "abstract": "Abstract Motivation Integrating Large Language Models (LLMs) with research tools presents technical and reproducibility challenges for biomedical research. While commercial artificial intelligence (AI) systems are easy to adopt, they obscure data provenance, lack transparency, and can generates false information, making them unfit for many research problems. To address these challenges, we developed the Bioinformatics Retrieval Augmented Digital (BRAD) agent software system. Results Here, we introduce BRAD, an agentic system that integrates LLMs with external tools and data to streamline research workflows. BRAD\u2019s modular agents retrieve information from literature, custom software, and online databases while maintaining transparent protocols to increase the reliability of AI generated results. We apply BRAD to a biomarker discovery pipeline, automating both execution and the generation of enrichment reports. This workflow contextualizes user data within the literature, enabling a level of interpretation and automation that surpasses conventional research tools. Beyond the workflow we highlight here, BRAD is a flexible system that has been deployed in other applications including a chatbot, video RAG, and analysis of single cell data. Availability and implementation The source code for BRAD is available at https://github.com/Jpickard1/BRAD; Information for pip installation, tutorials, documentation, and further information can be found at: ReadTheDocs.",
            "venue": "Bioinformatics",
            "paperUrl": "https://www.semanticscholar.org/paper/3ac8cac9583281d5eebca6a17e00af015eb8b286",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1093/bioinformatics/btaf159",
            "reason_for_inclusion": "High quality: Published in Bioinformatics, a reputable Q1 journal."
        },
        {
            "year": "2025.05",
            "title": "Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution",
            "team": "Mengdi Wang",
            "team website": "https://mwang.princeton.edu/",
            "affiliation": "",
            "domain": "General Scientific Research(self-evolution and create MCP)",
            "venue": "bioRxiv",
            "paperUrl": "https://arxiv.org/abs/2505.20286",
            "codeUrl": "https://github.com/CharlesQ9/Alita",
            "githubStars": "https://img.shields.io/github/stars/CharlesQ9/Alita",
            "doi": ""
        },
        {
            "year": "2025.05",
            "title": "BioOmni: A General-Purpose AI Agent for Automated Biomedical Research",
            "team": "Marinka Zitnik",
            "team website": "https://zitniklab.hms.harvard.edu/",
            "affiliation": "",
            "domain": "General Biomedical Research (Multi-modal)",
            "venue": "bioRxiv",
            "paperUrl": "https://www.biorxiv.org/content/10.1101/2025.05.30.656746v1",
            "codeUrl": "https://biomni.stanford.edu/",
            "githubStars": "https://img.shields.io/github/stars/snap-stanford/biomni",
            "doi": ""
        }
    ],
    "foundation-models": [
        {
            "year": "2025.05",
            "title": "sciLaMA: A Single-Cell Representation Learning Framework to Leverage Prior Knowledge from Large Language Models",
            "team": "G. Quon",
            "team website": "",
            "affiliation": "University of California, Davis",
            "domain": "Single-cell representation learning leveraging LLM prior knowledge",
            "abstract": "Single-cell RNA sequencing (scRNA-seq) enables high-resolution exploration of cellular diversity and gene regulation, yet analyzing such data remains challenging due to technical and methodological limitations. Existing task-specific deep generative models like Variational Auto-Encoder (VAE) and its variants struggle to incorporate external biological knowledge, while transformer-based foundational large Language Models (LLMs or large LaMs) face limitations in computational cost and applicability to tabular gene expression data. Here, we introduce sciL-aMA (single-cell interpretable Language Model Adapter), a novel representation learning frame-work that bridges these gaps by integrating static gene embeddings from multimodal LLMs with scRNA-seq tabular data through a paired-VAE architecture. Our approach generates context-aware representations for both cells and genes and outperforms state-of-the-art methods in key single-cell downstream tasks, including batch effect correction, cell clustering, and cell-state-specific gene marker and module identification, while maintaining computational efficiency. sciL-aMA offers a computationally efficient, unified framework for comprehensive single-cell data analysis and biologically interpretable gene module discovery. Source code is available at https://github.com/microsoft/sciLaMA",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/9aab32b1ffef407d9918bcf6f7b87c930d45c3f7",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.01.28.635153",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2025.05",
            "title": "LlamaAffinity: A Predictive Antibody\u2013Antigen Binding Model Integrating Antibody Sequences with Llama3 Backbone Architecture",
            "team": "J. Chen",
            "team website": "",
            "affiliation": "University of Alabama at Birmingham",
            "domain": "Antibody\u2013antigen binding affinity prediction using LLM-based models",
            "abstract": "Antibody-facilitated immune responses are central to the body\u2019s defense against pathogens, viruses, and other foreign invaders. The ability of antibodies to specifically bind and neutralize antigens is vital for maintaining immunity. Over the past few decades, bioengineering advancements have significantly accelerated therapeutic antibody development. These antibody-derived drugs have shown remarkable efficacy, particularly in treating Cancer, SARS-Cov-2, autoimmune disorders, and infectious diseases. Traditionally, experimental methods for affinity measurement have been time-consuming and expensive. With the realm of Artificial Intelligence, in silico medicine has revolutionized; recent developments in machine learning, particularly the use of large language models (LLMs) for representing antibodies, have opened up new avenues for AI-based designing and improving affinity prediction. Herein, we present an advanced antibody-antigen binding affinity prediction model (LlamaAffinity), leveraging an open-source Llama 3 backbone and antibody sequence data employed from the Observed Antibody Space (OAS) database. The proposed approach significantly improved over existing state-of-the-art (SOTA) approaches (AntiFormer, AntiBERTa, AntiBERTy) across multiple evaluation metrics. Specifically, the model achieved an accuracy of 0.9640, an F1-score of 0.9643, a precision of 0.9702, a recall of 0.9586, and an AUC-ROC of 0.9936. Moreover, this strategy unveiled higher computational efficiency, with a five-fold average cumulative training time of only 0.46 hours, significantly lower than previous studies. LlamaAffinity defines a new benchmark for antibody-antigen binding affinity prediction, achieving advanced performance in the immunotherapies and immunoinformatics field. Furthermore, it can effectively assess binding affinities following novel antibody design, accelerating the discovery and optimization of therapeutic candidates.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/2478b5379054be98bb2b0f325bc474ff806f1ea6",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.05.28.653051",
            "reason_for_inclusion": "High quality: Pre-print from world-renowned research institution."
        },
        {
            "year": "2025.05",
            "title": "GRAPE: Heterogeneous Graph Representation Learning for Genetic Perturbation with Coding and Non-Coding Biotype",
            "team": "Stan Z. Li",
            "team website": "",
            "affiliation": "",
            "domain": "Graph representation learning for genetic perturbation integrating LLM and DNA features",
            "abstract": "Predicting genetic perturbations enables the identification of potentially crucial genes prior to wet-lab experiments, significantly improving overall experimental efficiency. Since genes are the foundation of cellular life, building gene regulatory networks (GRN) is essential to understand and predict the effects of genetic perturbations. However, current methods fail to fully leverage gene-related information, and solely rely on simple evaluation metrics to construct coarse-grained GRN. More importantly, they ignore functional differences between biotypes, limiting the ability to capture potential gene interactions. In this work, we leverage pre-trained large language model and DNA sequence model to extract features from gene descriptions and DNA sequence data, respectively, which serve as the initialization for gene representations. Additionally, we introduce gene biotype information for the first time in genetic perturbation, simulating the distinct roles of genes with different biotypes in regulating cellular processes, while capturing implicit gene relationships through graph structure learning (GSL). We propose GRAPE, a heterogeneous graph neural network (HGNN) that leverages gene representations initialized with features from descriptions and sequences, models the distinct roles of genes with different biotypes, and dynamically refines the GRN through GSL. The results on publicly available datasets show that our method achieves state-of-the-art performance.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/e8cd781a1d5b928a0ff4d5eb2c3d42fdefdd6239",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2505.03853",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2025.05",
            "title": "A visual\u2013omics foundation model to bridge histopathology with spatial transcriptomics",
            "team": "Guangyu Wang",
            "team website": "https://guangyuwanglab.github.io/web/",
            "affiliation": "",
            "domain": "histopathology and spatial single cell RNA",
            "venue": "Nature Methods",
            "paperUrl": "https://www.nature.com/articles/s41592-025-02707-1",
            "codeUrl": "https://github.com/GuangyuWangLab2021/Loki",
            "githubStars": "https://img.shields.io/github/stars/GuangyuWangLab2021/Loki",
            "doi": ""
        },
        {
            "year": "2025.05",
            "title": "GeneBreaker: Jailbreak Attacks against DNA Language Models with Pathogenicity Guidance",
            "team": "Mengdi Wang",
            "team website": "https://mwang.princeton.edu/",
            "affiliation": "",
            "domain": "Biosafety for DNA",
            "venue": "arXiv",
            "paperUrl": "https://arxiv.org/abs/2505.23839",
            "codeUrl": "https://github.com/zaixizhang/GeneBreaker",
            "githubStars": "https://img.shields.io/github/stars/zaixizhang/GeneBreaker",
            "doi": ""
        },
        {
            "year": "2025.05",
            "title": "BioReason: Incentivizing Multimodal Biological Reasoning within a DNA-LLM Model",
            "team": "Bo Wang",
            "team website": "https://github.com/bowang-lab",
            "affiliation": "",
            "domain": "DNA",
            "venue": "arXiv",
            "paperUrl": "https://arxiv.org/abs/2505.23579",
            "codeUrl": "https://github.com/bowang-lab/BioReason",
            "githubStars": "https://img.shields.io/github/stars/bowang-lab/BioReason",
            "doi": ""
        },
        {
            "year": "2025.05",
            "title": "CellFM: a large-scale foundation model pre-trained on transcriptomics of 100 million human cells",
            "team": "",
            "team website": "",
            "affiliation": "",
            "domain": "single cell RNA",
            "venue": "Nature Communications",
            "paperUrl": "https://www.nature.com/articles/s41467-025-59926-5",
            "codeUrl": "https://github.com/biomed-AI/CellFM",
            "githubStars": "https://img.shields.io/github/stars/biomed-AI/CellFM",
            "doi": ""
        }
    ],
    "reviews": [
        {
            "year": "2025.05",
            "title": "Empowering Biomedical Research with Foundation Models in Computational Microscopy: A Systematic Review",
            "team": "Rong Luo",
            "team website": "",
            "affiliation": "",
            "domain": "Foundation models in computational microscopy",
            "abstract": "The integration of foundation models in artificial intelligence (AI) is transforming computational microscopy, driving significant advancements in biomedical research. Trained on extensive and diverse datasets, these models overcome critical limitations of traditional microscopy, such as low resolution, slow processing speeds, and difficulties in analyzing complex, high\u2010dimensional biological data. Foundation models enable enhanced image resolution, accelerated data processing, and real\u2010time analysis of dynamic biological processes. Despite these advancements, challenges persist, including concerns related to data quality, model generalizability across varied biological contexts, and the interpretability of AI\u2010generated insights. This review explores the application of foundation models in computational microscopy, emphasizing their theoretical foundations and practical implications across biomedical disciplines. Key obstacles are identified, such as the requirement for large\u2010scale, high\u2010quality annotated datasets and the need for model adaptation to specific clinical and preclinical settings. The review highlights the transformative potential of foundation models in advancing precision medicine, improving disease diagnostics, and enabling innovative therapeutic strategies, ultimately reshaping the landscape of biomedical research.",
            "venue": "Advanced Intelligent Systems",
            "paperUrl": "https://www.semanticscholar.org/paper/c1a1785a284ae67ac3fcdfa4fc096a589762e3e2",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1002/aisy.202500154",
            "reason_for_inclusion": "High quality: Published in Advanced Intelligent Systems, a reputable journal."
        },
        {
            "year": "2025.05",
            "title": "Large Language Models in Bioinformatics: A Survey",
            "team": "",
            "team website": "",
            "affiliation": "",
            "domain": "Bioinformatics foundation models",
            "venue": "arXiv",
            "paperUrl": "https://arxiv.org/abs/2503.04490",
            "codeUrl": "",
            "githubStars": "",
            "doi": ""
        }
    ],
    "benchmarks": [
        {
            "year": "2025.05",
            "title": "The influence of prompt engineering on large language models for protein\u2013protein interaction identification in biomedical literature",
            "team": "Yi-Hsuan Lin",
            "team website": "",
            "affiliation": "",
            "domain": "Prompt engineering of LLMs for protein-protein interaction extraction",
            "abstract": "Identifying protein\u2013protein interactions (PPIs) is a foundational task in biomedical natural language processing. While specialized models have been developed, the potential of general-domain large language models (LLMs) in PPI extraction, particularly for researchers without computational expertise, remains unexplored. This study evaluates the effectiveness of proprietary LLMs (GPT-3.5, GPT-4, and Google Gemini) in PPI prediction through systematic prompt engineering. We designed six prompting scenarios of increasing complexity, from basic interaction queries to sophisticated entity-tagged formats, and assessed model performance across multiple benchmark datasets (LLL, IEPA, HPRD50, AIMed, BioInfer, and PEDD). Carefully designed prompts effectively guided LLMs in PPI prediction. Gemini 1.5 Pro achieved the highest performance across most datasets, with notable F1-scores in LLL (90.3%), IEPA (68.2%), HPRD50 (67.5%), and PEDD (70.2%). GPT-4 showed competitive performance, particularly in the LLL dataset (87.3%). We identified and addressed a positive prediction bias, demonstrating improved performance after evaluation refinement. While not surpassing specialized models, general-purpose LLMs with appropriate prompting strategies can effectively perform PPI prediction tasks, offering valuable tools for biomedical researchers without extensive computational expertise. Supplementary Information The online version contains supplementary material available at 10.1038/s41598-025-99290-4.",
            "venue": "Scientific Reports",
            "paperUrl": "https://www.semanticscholar.org/paper/8738c78f5a2c2d94dcfc34ada047ed7e51dfbe8a",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s41598-025-99290-4",
            "reason_for_inclusion": "High quality: Published in Scientific Reports, a reputable journal."
        },
        {
            "year": "2025.05",
            "title": "CellVerse: Do Large Language Models Really Understand Cell Biology?",
            "team": "P. Heng",
            "team website": "",
            "affiliation": "",
            "domain": "LLMs for language-driven single-cell multi-omics analysis (CellVerse)",
            "abstract": "Recent studies have demonstrated the feasibility of modeling single-cell data as natural languages and the potential of leveraging powerful large language models (LLMs) for understanding cell biology. However, a comprehensive evaluation of LLMs' performance on language-driven single-cell analysis tasks still remains unexplored. Motivated by this challenge, we introduce CellVerse, a unified language-centric question-answering benchmark that integrates four types of single-cell multi-omics data and encompasses three hierarchical levels of single-cell analysis tasks: cell type annotation (cell-level), drug response prediction (drug-level), and perturbation analysis (gene-level). Going beyond this, we systematically evaluate the performance across 14 open-source and closed-source LLMs ranging from 160M to 671B on CellVerse. Remarkably, the experimental results reveal: (1) Existing specialist models (C2S-Pythia) fail to make reasonable decisions across all sub-tasks within CellVerse, while generalist models such as Qwen, Llama, GPT, and DeepSeek family models exhibit preliminary understanding capabilities within the realm of cell biology. (2) The performance of current LLMs falls short of expectations and has substantial room for improvement. Notably, in the widely studied drug response prediction task, none of the evaluated LLMs demonstrate significant performance improvement over random guessing. CellVerse offers the first large-scale empirical demonstration that significant challenges still remain in applying LLMs to cell biology. By introducing CellVerse, we lay the foundation for advancing cell biology through natural languages and hope this paradigm could facilitate next-generation single-cell analysis.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/4dd1c628a26c7b13c98e975c7ae8b5c16fbc320e",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2505.07865",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2025.05",
            "title": "Large Language Models Can Extract Metadata for Annotation of Human Neuroimaging Publications",
            "team": "Jessica A Turner",
            "team website": "",
            "affiliation": "Ohio State University Wexner Medical Center, Columbus, OH, USA",
            "domain": "LLM extraction and annotation of neuroimaging metadata",
            "abstract": "We show that recent (mid-to-late 2024) commercial large language models (LLMs) are capable of good quality metadata extraction and annotation with very little work on the part of investigators for several exemplar real-world annotation tasks in the neuroimaging literature. We investigated the GPT-4o LLM from OpenAI which performed comparably with several groups of specially trained and supervised human annotators. The LLM achieves similar performance to humans, between 0.91 and 0.97 on zero-shot prompts without feedback to the LLM. Reviewing the disagreements between LLM and gold standard human annotations we note that actual LLM errors are comparable to human errors in most cases, and in many cases these disagreements are not errors. Based on the specific types of annotations we tested, with exceptionally reviewed gold-standard correct values, the LLM performance is usable for metadata annotation at scale. We encourage other research groups to develop and make available more specialized \u201cmicro-benchmarks,\u201d like the ones we provide here, for testing both LLMs, and more complex agent systems annotation performance in real-world metadata annotation tasks.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/59087a91539883877289ceb562272f1cc13e9545",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.05.13.653828",
            "reason_for_inclusion": "High quality: Pre-print from world-renowned research institution."
        },
        {
            "year": "2025.05",
            "title": "scDrugMap: Benchmarking Large Foundation Models for Drug Response Prediction",
            "team": "Qianqian Song",
            "team website": "",
            "affiliation": "",
            "domain": "Benchmarking foundation models for single-cell drug response prediction",
            "abstract": "Drug resistance remains a significant barrier to improving the effectiveness of cancer therapies. To better understand the biological mechanisms driving resistance, single-cell profiling has emerged as a powerful tool for characterizing cellular heterogeneity. Recent advancements in large-scale foundation models have demonstrated potential in enhancing single-cell analysis, yet their performance in drug response prediction remains underexplored. In this study, we developed scDrugMap, an integrated framework for drug response prediction that features both a Python command-line tool and an interactive web server. scDrugMap supports the evaluation of a wide range of foundation models, including eight single-cell foundation models and two large language models (LLMs), using large-scale single-cell datasets across diverse tissue types, cancer types, and treatment regimens. The framework incorporates a curated data resource consisting of a primary collection of 326,751 cells from 36 datasets across 23 studies, and a validation collection of 18,856 cells from 17 datasets across 6 studies. Using scDrugMap, we conducted comprehensive benchmarking under two evaluation scenarios: pooled-data evaluation and cross-data evaluation. In both settings, we implemented two model training strategies\u2014layer freezing and fine-tuning using Low-Rank Adaptation (LoRA) of foundation models. In the pooled-data evaluation, scFoundation outperformed all others, while most models achieved competitive performance. Specifically, scFoundation achieved the highest mean F1 scores of 0.971 and 0.947 using layer-freezing and fine-tuning, outperforming the lowest-performing model by 54% and 57%, respectively. In the cross-data evaluation, UCE achieved the highest performance (mean F1 score: 0.774) after fine-tuning on tumor tissue, while scGPT demonstrated superior performance (mean F1 score: 0.858) in a zero-shot learning setting. Together, this study presents the first comprehensive benchmarking of large-scale foundation models for drug response prediction in single-cell data and introduces a user-friendly, flexible platform to support drug discovery and translational research.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/2dde8c82b5b59d46224f68e760ce5965a847e9c2",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2505.05612",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        }
    ],
    "databases": [
        {
            "year": "2025.05",
            "title": "scCompass: An Integrated Multi\u2010Species scRNA\u2010seq Database for AI\u2010Ready",
            "team": "Yuanchun Zhou",
            "team website": "",
            "affiliation": "",
            "domain": "Multi-species scRNA-seq database for AI-ready applications",
            "abstract": "Abstract Emerging single\u2010cell sequencing technology has generated large amounts of data, allowing analysis of cellular dynamics and gene regulation at the single\u2010cell resolution. Advances in artificial intelligence enhance life sciences research by delivering critical insights and optimizing data analysis processes. However, inconsistent data processing quality and standards remain to be a major challenge. Here scCompass is proposed, which provides a comprehensive resource designed to build large\u2010scale, multi\u2010species, and model\u2010friendly single\u2010cell data collection. By applying standardized data pre\u2010processing, scCompass integrates and curates transcriptomic data from nearly 105 million single cells across 13 species. Using this extensive dataset, it is able to identify stable expression genes (SEGs) and organ\u2010specific expression genes (OSGs) in humans and mice. Different scalable datasets are provided that can be easily adapted for AI model training and the pretrained checkpoints with state\u2010of\u2010the\u2010art single\u2010cell foundation models. In summary, scCompass is highly efficient and scalable database for AI\u2010ready, which combined with user\u2010friendly data sharing, visualization, and online analysis, greatly simplifies data access and exploitation for researchers in single\u2010cell biology (http://www.bdbe.cn/kun).",
            "venue": "Advanced Science",
            "paperUrl": "https://www.semanticscholar.org/paper/f5af8e3f7acd968b7baeb788f5b33cf7d868616e",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1002/advs.202500870",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2025.05",
            "title": "AlphaLasso\u2014a web server to identify loop and lasso motifs in 3D structure of biopolymers",
            "team": "Joanna I. Sulkowska",
            "team website": "",
            "affiliation": "",
            "domain": "Web server for lasso motifs in biopolymer 3D structures (AlphaLasso)",
            "abstract": "Abstract With the growing number of AI-predicted protein structures, automated methods of broad-scale analysis are required to parse this volume of data. The application of mathematically defined topologies to protein science enables such analysis. Building on the foundation of lasso peptides, complex lasso motifs are their macroscopic analogs in proteins, promising novel discoveries in drug design and the biopolymer industry. Here we present AlphaLasso, a web server designed to find and analyze lasso-type topologies in protein structures. It finds cysteine, amide, ester, and thioester or user-specified closing bridges. The modern visualization interface provides extensive capabilities to study lasso motifs, such as structure smoothing, creating topology maps, searching for similar proteins, in-depth model evaluation, and metadata annotation. This rich feature set makes AlphaLasso a powerful tool useful in biology, biophysics, chemistry, and mathematics. To enable large-scale analysis, we have precomputed the lasso topologies of high-quality models from the AlphaFold Database, finding >14 million proteins with lasso motifs closed by cysteine bridges, 2.2 million of which are complex lassos. Lasso motifs classified by complexity are available to users via an interactive website, supporting comparison with user-submitted structures. AlphaLasso is available at https://alphalasso.cent.uw.edu.pl/.",
            "venue": "Nucleic Acids Research",
            "paperUrl": "https://www.semanticscholar.org/paper/b2f16f79e6dc815d09b2892db7d3ca1d8a766478",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1093/nar/gkaf375",
            "reason_for_inclusion": "High quality: Published in Nucleic Acids Research, a top-tier journal."
        }
    ]
}