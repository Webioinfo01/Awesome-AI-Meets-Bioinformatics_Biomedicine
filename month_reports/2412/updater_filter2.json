{
    "ai-agents": [
        {
            "year": "2024.12",
            "title": "ProtChat: An AI Multi-Agent for Automated Protein Analysis Leveraging GPT-4 and Protein Language Model",
            "team": "Yunpeng Cai",
            "team website": "",
            "affiliation": "",
            "domain": "Automated protein analysis AI agent",
            "abstract": "Large language models (LLMs) have transformed natural language processing, enabling advanced human-machine communication. Similarly, in computational biology, protein sequences are interpreted as natural language, facilitating the creation of protein large language models (PLLMs). However, applying PLLMs requires specialized preprocessing and script development, increasing the complexity of their use. Researchers have integrated LLMs with PLLMs to develop automated protein analysis tools to address these challenges, simplifying analytical workflows. Existing technologies often require substantial human intervention for specific protein-related tasks, maintaining high barriers to implementing automated protein analysis systems. Here, we propose ProtChat, an AI multiagent system for protein analysis that integrates the inference capabilities of PLLMs with the task-planning abilities of LLMs. ProtChat integrates GPT-4 with multiple PLLMs, like ESM and MASSA, to automate tasks such as protein property prediction and protein-drug interactions without human intervention. This AI agent enables users to input instructions directly, significantly improving efficiency and usability, making it suitable for researchers without a computational background. Experiments demonstrate that ProtChat can automate complex protein tasks accurately, avoiding manual intervention and delivering results rapidly. This advancement opens new research avenues in computational biology and drug discovery. Future applications may extend ProtChat's capabilities to broader biological data analysis. Our code and data are publicly available at github.com/SIAT-code/ProtChat.",
            "venue": "Journal of chemical information and modeling",
            "paperUrl": "https://www.semanticscholar.org/paper/c89cfdd40cf24c40b09304cbbf85024933def10c",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1021/acs.jcim.4c01345",
            "reason_for_inclusion": "High quality: Published in Journal of Chemical Information and Modeling, a top-tier Q1 journal."
        },
        {
            "year": "2024.12",
            "title": "SCREADER: Prompting Large Language Models to Interpret scRNA-seq Data",
            "team": "Meng Xiao",
            "team website": "",
            "affiliation": "",
            "domain": "scRNA-seq interpretation via LLM prompting",
            "abstract": "Large language models (LLMs) have demonstrated remarkable advancements, primarily due to their capabilities in modeling the hidden relationships within text sequences. This innovation presents a unique opportunity in the field of life sciences, where vast collections of single-cell omics data from multiple species provide a foundation for training foundational models. However, the challenge lies in the disparity of data scales across different species, hindering the development of a comprehensive model for interpreting genetic data across diverse organisms. In this study, we propose an innovative hybrid approach that integrates the general knowledge capabilities of LLMs with domain-specific representation models for single-cell omics data interpretation. We begin by focusing on genes as the fundamental unit of representation. Gene representations are initialized using functional descriptions, leveraging the strengths of mature language models such as LLaMA-2. By inputting single-cell gene-level expression data with prompts, we effectively model cellular representations based on the differential expression levels of genes across various species and cell types. In the experiments, we constructed developmental cells from humans and mice, specifically targeting cells that are challenging to annotate. We evaluated our methodology through basic tasks such as cell annotation and visualization analysis. The results demonstrate the efficacy of our approach compared to other methods using LLMs, highlighting significant improvements in accuracy and interoperability. Our hybrid approach enhances the representation of single-cell data and offers a robust framework for future research in cross-species genetic analysis. 1",
            "venue": "2024 IEEE International Conference on Data Mining Workshops (ICDMW)",
            "paperUrl": "https://www.semanticscholar.org/paper/aba63c2f387349a58bbc9a89d83e2018bc436819",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1109/ICDMW65004.2024.00092",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2024.12",
            "title": "SciAgents: Automating Scientific Discovery Through Bioinspired Multi\u2010Agent Intelligent Graph Reasoning",
            "team": "Markus J. Buehler",
            "team website": "",
            "affiliation": "",
            "domain": "Multi-agent AI for automated materials discovery",
            "abstract": "A key challenge in artificial intelligence (AI) is the creation of systems capable of autonomously advancing scientific understanding by exploring novel domains, identifying complex patterns, and uncovering previously unseen connections in vast scientific data. In this work, SciAgents, an approach that leverages three core concepts is presented: (1) large\u2010scale ontological knowledge graphs to organize and interconnect diverse scientific concepts, (2) a suite of large language models (LLMs) and data retrieval tools, and (3) multi\u2010agent systems with in\u2010situ learning capabilities. Applied to biologically inspired materials, SciAgents reveals hidden interdisciplinary relationships that were previously considered unrelated, achieving a scale, precision, and exploratory power that surpasses human research methods. The framework autonomously generates and refines research hypotheses, elucidating underlying mechanisms, design principles, and unexpected material properties. By integrating these capabilities in a modular fashion, the system yields material discoveries, critiques and improves existing hypotheses, retrieves up\u2010to\u2010date data about existing research, and highlights strengths and limitations. This is achieved by harnessing a \u201cswarm of intelligence\u201d similar to biological systems, providing new avenues for discovery. How this model accelerates the development of advanced materials by unlocking Nature's design principles, resulting in a new biocomposite with enhanced mechanical properties and improved sustainability through energy\u2010efficient production is shown.",
            "venue": "Advanced Materials (Deerfield Beach, Fla.)",
            "paperUrl": "https://www.semanticscholar.org/paper/dbbcdb281ed6aa646af0402172cf8a7cfda85d5c",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1002/adma.202413523",
            "reason_for_inclusion": "High quality: Published in Advanced Materials, a top-tier journal."
        },
        {
            "year": "2024.12",
            "title": "Development and Application of an In Vitro Drug Screening Assay for Schistosoma mansoni Schistosomula Using YOLOv5",
            "team": "Antonio Muro",
            "team website": "",
            "affiliation": "",
            "domain": "AI-powered drug screening assay for schistosomula",
            "abstract": "Background: Schistosomiasis impacts over 230 million people globally, with 251.4 million needing treatment. The disease causes intestinal and urinary symptoms, such as hepatic fibrosis, hepatomegaly, splenomegaly, and bladder calcifications. While praziquantel (PZQ) is the primary treatment, its effectiveness against juvenile stages (schistosomula) is limited, highlighting the need for new therapeutic agents, repurposed drugs, or reformulated compounds. Existing microscopy methods for assessing schistosomula viability are labor-intensive, subjective, and time-consuming. Methods: An artificial intelligence (AI)-assisted culture system using YOLOv5 was developed to evaluate compounds against Schistosoma mansoni schistosomula. The AI model, based on object detection, was trained on 4390 images distinguishing between healthy and damaged schistosomula. The system was externally validated against human counters, and a small-scale assay was performed to demonstrate its potential for larger-scale assays in the future. Results: The AI model exhibited high accuracy, achieving a mean average precision (mAP) of 0.966 (96.6%) and effectively differentiating between healthy and damaged schistosomula. External validation demonstrated significantly improved accuracy and counting time compared to human counters. A small-scale assay was conducted to validate the system, identifying 28 potential compounds with schistosomicidal activity against schistosomula in vitro and providing their preliminary LC50 values. Conclusions: This AI-powered method significantly improves accuracy and time efficiency compared to traditional microscopy. It enables the evaluation of compounds for potential schistosomiasis drugs without the need for dyes or specialized equipment, facilitating more efficient drug assessment.",
            "venue": "Biomedicines",
            "paperUrl": "https://www.semanticscholar.org/paper/0cac159098bb2365ca8547979f6f81018165a0ca",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.3390/biomedicines12122894",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2024.12",
            "title": "CASSIA: a multi-agent large language model for reference free, interpretable, and automated cell annotation of single-cell RNA-sequencing data",
            "team": "",
            "team website": "",
            "affiliation": "",
            "domain": "Single Cell annotation",
            "venue": "bioRxiv",
            "paperUrl": "https://www.biorxiv.org/content/10.1101/2024.12.04.626476v2",
            "codeUrl": "https://github.com/ElliotXie/CASSIA",
            "githubStars": "https://img.shields.io/github/stars/ElliotXie/CASSIA",
            "doi": "",
            "abstract": "",
            "reason_for_inclusion": ""
        }
    ],
    "foundation-models": [
        {
            "year": "2024.12",
            "title": "L2G: Repurposing Language Models for Genomics Tasks",
            "team": "Ameet Talwalkar",
            "team website": "",
            "affiliation": "Carnegie Mellon University",
            "domain": "Repurposing LLMs for genomics tasks",
            "abstract": "Pre-trained language models have transformed the field of natural language processing (NLP), and their success has inspired efforts in genomics to develop domain-specific foundation models (FMs). However, creating high-quality genomic FMs from scratch is resource-intensive, requiring significant computational power and high-quality pre-training data. The success of large language models (LLMs) in NLP has largely been driven by industrial-scale efforts leveraging vast, diverse corpora and massive computing infrastructure. In this work, we aim to bypass the data and computational bottlenecks of creating genomic FMs from scratch and instead propose repurposing existing LLMs for genomics tasks. Inspired by the recently observed \u2018cross-modal transfer\u2019 phenomenon \u2013 where transformers pre-trained on natural language can generalize to other modalities \u2013 we introduce L2G, which adapts a pre-trained LLM architecture for genomics using neural architecture search (NAS) and a novel three-stage training procedure. Remarkably, without requiring extensive pre-training on DNA sequence data, L2G achieves superior performance to fine-tuned genomic FMs and task-specific models on more than half of tasks across multiple genomics benchmarks. In an enhancer activity prediction task, L2G further demonstrates its capacity to identify significant transcription factor motifs. Our work not only highlights the generalizability and efficacy of language models in out-of-domain tasks such as genomics, but also opens new avenues for more efficient and less resource-intensive methodologies in genomic research.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/238d842ee1679545e00d212a342f271a05473eaf",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2024.12.09.627422",
            "reason_for_inclusion": "High quality: Preprint from Carnegie Mellon University, a world-renowned institution."
        },
        {
            "year": "2024.12",
            "title": "Fine-Tuned Deep Transfer Learning Models for Large Screenings of Safer Drugs Targeting Class A GPCRs",
            "team": "M. Filizola",
            "team website": "",
            "affiliation": "Icahn School of Medicine at Mount Sinai",
            "domain": "Deep transfer learning for GPCR drug screening",
            "abstract": "",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/adfd39e5060b00b74a38d7b7243f60af2934e966",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2024.12.07.627102",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2024.12",
            "title": "Porter 6: Protein Secondary Structure Prediction by Leveraging Pre-Trained Language Models (PLMs)",
            "team": "G. Pollastri",
            "team website": "",
            "affiliation": "",
            "domain": "Protein secondary structure prediction with PLMs",
            "abstract": "Accurately predicting protein secondary structure (PSSP) is crucial for understanding protein function, which is foundational to advancements in drug development, disease treatment, and biotechnology. Researchers gain critical insights into protein folding and function within cells by predicting protein secondary structures. The advent of deep learning models, capable of processing complex sequence data and identifying meaningful patterns, offer substantial potential to enhance the accuracy and efficiency of protein structure predictions. In particular, recent breakthroughs in deep learning\u2014driven by the integration of natural language processing (NLP) algorithms\u2014have significantly advanced the field of protein research. Inspired by the remarkable success of NLP techniques, this study harnesses the power of pre-trained language models (PLMs) to advance PSSP prediction. We conduct a comprehensive evaluation of various deep learning models trained on distinct sequence embeddings, including one-hot encoding and PLM-based approaches such as ProtTrans and ESM-2, to develop a cutting-edge prediction system optimized for accuracy and computational efficiency. Our proposed model, Porter 6, is an ensemble of CBRNN-based predictors, leveraging the protein language model ESM-2 as input features. Porter 6 achieves outstanding performance on large-scale, independent test sets. On a 2022 test set, the model attains an impressive 86.60% accuracy in three-state (Q3) and 76.43% in eight-state (Q8) classifications. When tested on a more recent 2024 test set, Porter 6 maintains robust performance, achieving 84.56% in Q3 and 74.18% in Q8 classifications. This represents a significant 3% improvement over its predecessor, outperforming or matching state-of-the-art approaches in the field.",
            "venue": "International Journal of Molecular Sciences",
            "paperUrl": "https://www.semanticscholar.org/paper/4eb9efc6ea3f7bf7935c374940af4c3866a5a368",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.3390/ijms26010130",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2024.12",
            "title": "ProtDAT: A Unified Framework for Protein Sequence Design from Any Protein Text Description",
            "team": "Hong-Bin Shen",
            "team website": "",
            "affiliation": "",
            "domain": "Multi-modal protein sequence design from text",
            "abstract": "Protein design has become a critical method in advancing significant potential for various applications such as drug development and enzyme engineering. However, protein design methods utilizing large language models with solely pretraining and fine-tuning struggle to capture relationships in multi-modal protein data. To address this, we propose ProtDAT, a de novo fine-grained framework capable of designing proteins from any descriptive protein text input. ProtDAT builds upon the inherent characteristics of protein data to unify sequences and text as a cohesive whole rather than separate entities. It leverages an innovative multi-modal cross-attention, integrating protein sequences and textual information for a foundational level and seamless integration. Experimental results demonstrate that ProtDAT achieves the state-of-the-art performance in protein sequence generation, excelling in rationality, functionality, structural similarity, and validity. On 20,000 text-sequence pairs from Swiss-Prot, it improves pLDDT by 6%, TM-score by 0.26, and reduces RMSD by 1.2 {\\AA}, highlighting its potential to advance protein design.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/1fc064d589849dfefce0d28fe64b9b83600a0cb6",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2412.04069",
            "reason_for_inclusion": "Included to meet target filter limit."
        }
    ],
    "reviews": [
        {
            "year": "2024.12",
            "title": "Large language models facilitating modern molecular biology and novel drug development",
            "team": "Fei Liu",
            "team website": "",
            "affiliation": "",
            "domain": "Review of LLMs in molecular biology and drug development",
            "abstract": "The latest breakthroughs in information technology and biotechnology have catalyzed a revolutionary shift within the modern healthcare landscape, with notable impacts from artificial intelligence (AI) and deep learning (DL). Particularly noteworthy is the adept application of large language models (LLMs), which enable seamless and efficient communication between scientific researchers and AI systems. These models capitalize on neural network (NN) architectures that demonstrate proficiency in natural language processing, thereby enhancing interactions. This comprehensive review outlines the cutting-edge advancements in the application of LLMs within the pharmaceutical industry, particularly in drug development. It offers a detailed exploration of the core mechanisms that drive these models and zeroes in on the practical applications of several models that show great promise in this domain. Additionally, this review delves into the pivotal technical and ethical challenges that arise with the practical implementation of LLMs. There is an expectation that LLMs will assume a more pivotal role in the development of innovative drugs and will ultimately contribute to the accelerated development of revolutionary pharmaceuticals.",
            "venue": "Frontiers in Pharmacology",
            "paperUrl": "https://www.semanticscholar.org/paper/d7157f73a59c3a619549217e6d27884bebedf419",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.3389/fphar.2024.1458739",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2024.12",
            "title": "From multi-omics to predictive biomarker: AI in tumor microenvironment",
            "team": "Yingli Sun",
            "team website": "",
            "affiliation": "",
            "domain": "Review of AI in tumor microenvironment multi-omics",
            "abstract": "In recent years, tumors have emerged as a major global health threat. An increasing number of studies indicate that the production, development, metastasis, and elimination of tumor cells are closely related to the tumor microenvironment (TME). Advances in artificial intelligence (AI) algorithms, particularly in large language models, have rapidly propelled research in the medical field. This review focuses on the current state and strategies of applying AI algorithms to tumor metabolism studies and explores expression differences between tumor cells and normal cells. The analysis is conducted from the perspectives of metabolomics and interactions within the TME, further examining the roles of various cytokines. This review describes the potential approaches through which AI algorithms can facilitate tumor metabolic studies, which offers a valuable perspective for a deeper understanding of the pathological mechanisms of tumors.",
            "venue": "Frontiers in Immunology",
            "paperUrl": "https://www.semanticscholar.org/paper/6ae86bc78b187c0ca15b977156b8a2bd41d91be9",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.3389/fimmu.2024.1514977",
            "reason_for_inclusion": "High quality: Published in Frontiers in Immunology, a reputable Q1 journal."
        },
        {
            "year": "2024.12",
            "title": "Advancements and Applications of Protein Structure Prediction Algorithms",
            "team": "Ye Chen",
            "team website": "",
            "affiliation": "",
            "domain": "Review of protein structure prediction methods",
            "abstract": "Protein structure prediction serves as a foundational aspect of molecular biology, where computational advancements have recently propelled significant increases in prediction accuracy. This paper evaluates traditional protein structure prediction methods, including homology modeling, threading, and Ab Initio techniques, emphasizing the inherent challenges these methods face in accurately modeling novel and highly flexible proteins. With the advent of AI-based models, particularly AlphaFold, the landscape of protein structure prediction has undergone a transformative shift. AlphaFold integrates evolutionary data with sophisticated deep learning algorithms to achieve accuracies close to experimental results. Despite such progress, AlphaFold grapples with challenges in dynamic regions of proteins, such as intrinsically disordered proteins (IDPs), and struggles to accurately predict the structural impacts of genetic mutations. The paper also explores novel emerging methods, such as protein language models, designed to address these specific limitations. These cutting-edge approaches not only enhance the accuracy of protein structure predictions but also broaden the scope of potential applications. Areas such as drug discovery and vaccine development stand to benefit immensely from these advancements, potentially expediting critical breakthroughs. This examination of both established and novel methodologies illuminates the ongoing evolution of protein structure prediction, pointing towards future innovations that may further revolutionize the field.",
            "venue": "Theoretical and Natural Science",
            "paperUrl": "https://www.semanticscholar.org/paper/6567678e2b6869ead0953704efdb926294daeebb",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.54254/2753-8818/2024.la18791",
            "reason_for_inclusion": "Included to meet target filter limit."
        }
    ],
    "databases": [
        {
            "year": "2024.12",
            "title": "M3-20M: A Large-Scale Multi-Modal Molecule Dataset for AI-driven Drug Design and Discovery",
            "team": "Shuigeng Zhou",
            "team website": "",
            "affiliation": "",
            "domain": "Multi-modal molecule dataset for drug design",
            "abstract": "This paper introduces M3-20M, a large-scale Multi-Modal Molecule dataset that contains over 20 million molecules, with the data mainly being integrated from existing databases and partially generated by large language models. Designed to support AI-driven drug design and discovery, M3-20M is 71 times more in the number of molecules than the largest existing dataset, providing an unprecedented scale that can highly benefit the training or fine-tuning of models, including large language models for drug design and discovery tasks. This dataset integrates one-dimensional SMILES, two-dimensional molecular graphs, three-dimensional molecular structures, physicochemical properties, and textual descriptions collected through web crawling and generated using GPT-3.5, offering a comprehensive view of each molecule. To demonstrate the power of M3-20M in drug design and discovery, we conduct extensive experiments on two key tasks: molecule generation and molecular property prediction, using large language models including GLM4, GPT-3.5, GPT-4, and Llama3-8b. Our experimental results show that M3-20M can significantly boost model performance in both tasks. Specifically, it enables the models to generate more diverse and valid molecular structures and achieve higher property prediction accuracy than existing single-modal datasets, which validates the value and potential of M3-20M in supporting AI-driven drug design and discovery. The dataset is available at https://github.com/bz99bz/M-3.",
            "venue": "Journal of bioinformatics and computational biology",
            "paperUrl": "https://www.semanticscholar.org/paper/aa3a1bbd4f6ec6934ce6a3850991747f563ab3b0",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2412.06847",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2024.12",
            "title": "BioMedGraphica: An All-in-One Platform for Biomedical Prior Knowledge and Omic Signaling Graph Generation",
            "team": "Fuhai Li",
            "team website": "",
            "affiliation": "Washington University in St. Louis",
            "domain": "Biomedical knowledge graph platform",
            "abstract": "Artificial intelligence (AI) is revolutionizing scientific discovery because of its super capability, following the neural scaling laws, to integrate and analyze large-scale datasets to mine knowledge. Foundation models, large language models (LLMs) and large vision models (LVMs), are among the most important foundations paving the way for general AI by pre-training on massive domain-specific datasets. Different from the well annotated, formatted and integrated large textual and image datasets for LLMs and LVMs, biomedical knowledge and datasets are fragmented with data scattered across publications and inconsistent databases that often use diverse nomenclature systems in the field of AI for Precision Health and Medicine (AI4PHM). These discrepancies, spanning different levels of biomedical organization from genes to clinical traits, present major challenges for data integration and alignment. To facilitate foundation AI model development and applications in AI4PHM, herein, we developed BioMedGraphica, an all-in-one platform and unified text-attributed knowledge graph (TAKG), consists of 3,131,788 entities and 56,817,063 relations, which are obtained from 11 distinct entity types and harmonizes 29 relations/edge types using data from 43 biomedical databases. All entities and relations are labeled a unique ID and associated with textual descriptions (textual features). Since covers most of research entities in AI4PHM, BioMedGraphica supports the zero-shot or few-shot knowledge discoveries via new relation prediction on the graph. Via a graphical user interface (GUI), researchers can access the knowledge graph with prior knowledge of target functional annotations, drugs, phenotypes and diseases (drug-protein-disease-phenotype), in the graph AI ready format. It also supports the generation of knowledge-multi-omic signaling graphs to facilitate the development and applications of novel AI models, like LLMs, graph AI, for AI4PHM science discovery, like discovering novel disease pathogenesis, signaling pathways, therapeutic targets, drugs and synergistic cocktails.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/212898d49afdf60a12eeda9935bc54d748da3089",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2024.12.05.627020",
            "reason_for_inclusion": "High quality: Preprint from Washington University in St. Louis, a world-renowned institution."
        },
        {
            "year": "2024.12",
            "title": "Basic Science and Pathogenesis.",
            "team": "Li-San Wang",
            "team website": "",
            "affiliation": "",
            "domain": "AI-enhanced search for Alzheimer's genomic database",
            "abstract": "BACKGROUND\nNIAGADS is a national data repository that offers qualified investigators access to genomic data for Alzheimer's disease (AD) and related dementia. In addition, NIAGADS has made substantial effort to curate, harmonize, standardize, and disseminate AD-relevant variant, gene, and sequence annotations from publications, functional genomics datasets, and summary statistics deposited at NIAGADS. These results are made available to the public in a collection of interactive knowledgebases (AD Variant Portal, FILER Functional Genomics Repository, VariXam, Alzheimer's GenomicsDB & Genome Browser), all of which are accessible programmatically via the NIAGADS API. However, as these offerings grow, navigating them can be challenging. Here, we introduce AI-based enhancements to NIAGADS sites to help guide researchers and facilitate data discovery.\n\n\nMETHOD\nWe leverage OpenAI's generative AI to build and train three large language models (LLMs) based on NIAGADS documentation, step-by-step recipes for data-access requests, subject-specific vocabularies, and the OpenAPI specification defining the NIAGADS API that allows programmatic access to the NIAGADS knowledgebases. For users of the API and to enhance search interfaces, we build on the LLMs to construct a framework for handling complex natural language instructions that decomposes an inquiry into tasks and subtasks and then plans, selects, and optionally executes API calls and parses the results.\n\n\nRESULT\nDeveloping these LLMs allows NIAGADS to improve user experiences by integrating topic-specific chatbots and generative AI search tools into NIAGADS sites. Rule-based chatbots that leverage conversational AI on the NIAGADS portal and Data Sharing Service will respond to inquiries with answers inferred from the LLMs, with responses improving with user feedback. These bots will also supplement help requests, suggesting solutions to common inquiries. Planner-enhanced generative AI based on the API-specification trained LLMs will be tied to knowledgebase searches and filters in resources such as the GenomicsDB and FILER to allow users to leverage natural language processing to ask sophisticated questions that require multiple API calls to resolve the answer.\n\n\nCONCLUSION\nIntroducing AI-enhanced search creates an interactive opportunity for NIAGADS users to learn new information or discover resources and tools they can use to supplement their research, which, in turn, improves NIAGADS ability to support AD genetics research.",
            "venue": "Alzheimer's & dementia : the journal of the Alzheimer's Association",
            "paperUrl": "https://www.semanticscholar.org/paper/28d30ecee02ba1039bd83c77d3131c7c744dad26",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1002/alz.092685",
            "reason_for_inclusion": "High quality: Published in Alzheimer's & Dementia, a leading journal of the Alzheimer's Association."
        }
    ],
    "benchmarks": [
        {
            "year": "2024.12",
            "title": "Does your model understand genes? A benchmark of gene properties for biological and text models",
            "team": "Y. Shimoni",
            "team website": "",
            "affiliation": "",
            "domain": "Benchmark of gene property prediction models",
            "abstract": "The application of deep learning methods, particularly foundation models, in biological research has surged in recent years. These models can be text-based or trained on underlying biological data, especially omics data of various types. However, comparing the performance of these models consistently has proven to be a challenge due to differences in training data and downstream tasks. To tackle this problem, we developed an architecture-agnostic benchmarking approach that, instead of evaluating the models directly, leverages entity representation vectors from each model and trains simple predictive models for each benchmarking task. This ensures that all types of models are evaluated using the same input and output types. Here we focus on gene properties collected from professionally curated bioinformatics databases. These gene properties are categorized into five major groups: genomic properties, regulatory functions, localization, biological processes, and protein properties. Overall, we define hundreds of tasks based on these databases, which include binary, multi-label, and multi-class classification tasks. We apply these benchmark tasks to evaluate expression-based models, large language models, protein language models, DNA-based models, and traditional baselines. Our findings suggest that text-based models and protein language models generally outperform expression-based models in genomic properties and regulatory functions tasks, whereas expression-based models demonstrate superior performance in localization tasks. These results should aid in the development of more informed artificial intelligence strategies for biological understanding and therapeutic discovery. To ensure the reproducibility and transparency of our findings, we have made the source code and benchmark data publicly accessible for further investigation and expansion at github.com/BiomedSciAI/gene-benchmark.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/7eb6e6bce59f3e724ae3365b1348627dfd73c409",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2412.04075",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2024.12",
            "title": "PerturBench: Benchmarking Machine Learning Models for Cellular Perturbation Analysis",
            "team": "",
            "team website": "",
            "affiliation": "",
            "domain": "Perturbation scRNA",
            "venue": "NeurIPS 2024",
            "paperUrl": "https://neurips.cc/virtual/2024/102911",
            "codeUrl": "https://github.com/altoslabs/perturbench",
            "githubStars": "https://img.shields.io/github/stars/altoslabs/perturbench",
            "doi": "",
            "abstract": "",
            "reason_for_inclusion": ""
        }
    ]
}